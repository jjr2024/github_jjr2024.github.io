[
  {
    "objectID": "posts/new-test-post/index.html",
    "href": "posts/new-test-post/index.html",
    "title": "Second Post",
    "section": "",
    "text": "This is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/new-test-post/index.html#math",
    "href": "posts/new-test-post/index.html#math",
    "title": "Second Post",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "posts/example-blog-post/index.html",
    "href": "posts/example-blog-post/index.html",
    "title": "Hello Blog",
    "section": "",
    "text": "from source import Perceptron\nThis is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/example-blog-post/index.html#math",
    "href": "posts/example-blog-post/index.html#math",
    "title": "Hello Blog",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Awesome CSCI 0451 Blog",
    "section": "",
    "text": "Decision Making\n\n\n\n\n\nA blog post about optimal decisionmaking in the context of bank loans.\n\n\n\n\n\nMar 30, 2024\n\n\nJames Ohr\n\n\n\n\n\n\n\n\n\n\n\n\nImplementing the Perceptron Algorithm\n\n\n\n\n\nA blog post about implementing and testing the perceptron algorithm.\n\n\n\n\n\nMar 30, 2024\n\n\nJames Ohr\n\n\n\n\n\n\n\n\n\n\n\n\nClassifying Penguins\n\n\n\n\n\nA blog post about classifying penguin species based on physical characteristics.\n\n\n\n\n\nMar 29, 2024\n\n\nJames Ohr\n\n\n\n\n\n\n\n\n\n\n\n\nTimnit Gebru\n\n\n\n\n\nA new blog post that I just made!\n\n\n\n\n\nMar 10, 2023\n\n\nPhil Chodrow\n\n\n\n\n\n\n\n\n\n\n\n\nSecond Post\n\n\n\n\n\nA new blog post that I just made!\n\n\n\n\n\nMar 10, 2023\n\n\nPhil Chodrow\n\n\n\n\n\n\n\n\n\n\n\n\nHello Blog\n\n\n\n\n\nAn example blog post illustrating the key techniques you’ll need to demonstrate your learning in CSCI 0451.\n\n\n\n\n\nJan 10, 2023\n\n\nPhil Chodrow\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/new-new-test-post/index.html",
    "href": "posts/new-new-test-post/index.html",
    "title": "Timnit Gebru",
    "section": "",
    "text": "from source import Perceptron\np = Perceptron()\n\nI did it!!\nnot implemented\nThis is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/new-new-test-post/index.html#math",
    "href": "posts/new-new-test-post/index.html#math",
    "title": "Timnit Gebru",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "posts/decision-making/DecisionMaking.html",
    "href": "posts/decision-making/DecisionMaking.html",
    "title": "Decision Making",
    "section": "",
    "text": "Introduction: In this post, I analyze data, construct a logistic regression model, and make predictions on a test dataset to understand a simplified but relatively realistic decisionmaking process to find whether to make a loan to a borrower given information on their personal finances, their requested loan, and their employment history. I find a bank can maximize its profits by lending to a small number of higher-income individuals with smaller requested loans, longer credit histories, and more years of employment. Loans for different purposes have varying default rates and are correspondingly approved at different rates–medical loans in particular are more often rejected but have the highest default rates. Using a definition of fairness related to minimizing harm, I argue that it’s reasonable for a bank to have lower approval ratings for medical loans so it can minimize harm to its own stakeholders.\nI have neither given nor received unauthorized aid on this assignment - James Ohr\n\n\n\n#Importing the data and storing it in variable df_train\n\nimport pandas as pd\nurl = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/credit-risk/train.csv\"\ndf_train = pd.read_csv(url)\n\n\n\n\n\ndf_train.head()\n\n\n\n\n\n\n\n\n\nperson_age\nperson_income\nperson_home_ownership\nperson_emp_length\nloan_intent\nloan_grade\nloan_amnt\nloan_int_rate\nloan_status\nloan_percent_income\ncb_person_default_on_file\ncb_person_cred_hist_length\n\n\n\n\n0\n25\n43200\nRENT\nNaN\nVENTURE\nB\n1200\n9.91\n0\n0.03\nN\n4\n\n\n1\n27\n98000\nRENT\n3.0\nEDUCATION\nC\n11750\n13.47\n0\n0.12\nY\n6\n\n\n2\n22\n36996\nRENT\n5.0\nEDUCATION\nA\n10000\n7.51\n0\n0.27\nN\n4\n\n\n3\n24\n26000\nRENT\n2.0\nMEDICAL\nC\n1325\n12.87\n1\n0.05\nN\n4\n\n\n4\n29\n53004\nMORTGAGE\n2.0\nHOMEIMPROVEMENT\nA\n15000\n9.63\n0\n0.28\nN\n10\n\n\n\n\n\n\n\n\nThe above table helps me get a sense of the variables in the dataset and their types.\n\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\ng = sns.displot(df_train, x=\"loan_percent_income\", hue=\"loan_status\", element=\"step\", legend=False)\nplt.legend(title='Loan Status', loc='upper right', labels=['Default', 'No Default'])\ng.set(xlabel=\"Loan Proportion of Income\")\nplt.show(g)\n\n\n\n\n\n\n\n\nThe above figure shows that there are * significantly more borrowers who didn’t default than those who did * individuals who receive a loan less than 30% of their income are unlikely to default on their loan * individuals who receive a loan over 30% of their income are significantly more likely to default than not.\n\ng = sns.displot(df_train, x=\"loan_int_rate\", hue=\"loan_intent\", kind=\"kde\")\ng.legend.set_title(\"Loan Purpose\")\ng.set(xlabel=\"Loan Interest Rate (%)\")\nplt.show(g)\n\n\n\n\n\n\n\n\nThe above figure shows an interesting pattern across every single type of loan. Each distribution is approximately bimodal (although some have three local maxima). It’s unsurprising, but there are far more people under the second peak, i.e., the higher interest rate peak, for each type of loan.\n\ndf_train.groupby(\"loan_intent\").mean(numeric_only=True)\n\n\n\n\n\n\n\n\n\nperson_age\nperson_income\nperson_emp_length\nloan_amnt\nloan_int_rate\nloan_status\nloan_percent_income\ncb_person_cred_hist_length\n\n\nloan_intent\n\n\n\n\n\n\n\n\n\n\n\n\nDEBTCONSOLIDATION\n27.588798\n66693.453327\n4.759419\n9620.901149\n10.983305\n0.287458\n0.170869\n5.695548\n\n\nEDUCATION\n26.597620\n63847.711917\n4.440192\n9460.015604\n10.965465\n0.173396\n0.169352\n5.141603\n\n\nHOMEIMPROVEMENT\n28.981737\n73082.079600\n5.103754\n10348.725017\n11.160075\n0.264645\n0.166733\n6.430048\n\n\nMEDICAL\n27.950982\n61314.583868\n4.782062\n9242.269907\n11.051946\n0.263289\n0.172825\n5.913547\n\n\nPERSONAL\n28.288339\n68070.502495\n4.897997\n9549.427178\n11.009814\n0.193739\n0.168671\n6.151316\n\n\nVENTURE\n27.588643\n66098.818162\n4.877869\n9516.417425\n10.940866\n0.148678\n0.170130\n5.744040\n\n\n\n\n\n\n\n\nBorrowers intending to use loans for home improvement tend to: * have higher incomes * receive greater loans * tend to have higher default rates, which are in line with default rates of loans for medical and debt consolidation.\nMedical loan borrowers tend to have the lowest incomes, the highest loan-to-income ratios, and the lowest loan amounts. The first observation is most surprising–I would have expected education loan borrowers to have the lowest incomes (maybe this has to do with co-signers).\n\n\n\nThe below code pre-processes our data for use in the model. We drop the “loan_grade” variable, which the instructions disallow for building th emodel. We separate out “loan status” into an outcome variable, y. We transform categorical variables from strings into numbers.\n\n#Data pre-processing\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\n\ndef prepare_data(df):\n  df = df_train.drop([\"loan_grade\"], axis = 1)\n  df = df.dropna()\n  le.fit(df_train[\"person_home_ownership\"])\n  df[\"person_home_ownership\"] = le.transform(df[\"person_home_ownership\"])\n  le.fit(df_train[\"loan_intent\"])\n  df[\"loan_intent\"] = le.transform(df[\"loan_intent\"])\n  y = df[\"loan_status\"]\n  df = df.drop([\"loan_status\"], axis = 1)\n  df = pd.get_dummies(df)\n  return df, y\n\nX_train, y_train = prepare_data(df_train)\ndf_train = df_train.dropna()\n\nBelow, I chose the features for the model and fitted our model to our training data. I chose income and loan amount because they’re the two components of the loan-to-income ratio, which seemed to be relatively revealing in the above chart showing loan status vs. loan-to-income. Adding employment length didn’t actually change the accuracy of the model, but I added it just because intuitively I thought it might have an impact even though the table above didn’t show anything particularly interesting regarding the variable.\n\n#Choosing features\nfrom sklearn.linear_model import LogisticRegression\n\nLR = LogisticRegression()\n\ncols = [\"person_income\", \"loan_amnt\", \"person_emp_length\"]\n\nLR.fit(X_train[cols], y_train)\nLR.score(X_train[cols], y_train)\nLR.coef_[0]\n\narray([-4.05735465e-05,  1.06559046e-04, -2.48736069e-08])\n\n\n\n\n\nBelow we have code that (1) finds the profit the bank makes from all of its loans (we ignore any NAs) and (2) identifies the threshold that maximizes profit.\n\n#This function, taken from the week 2 lecture notes and just slightly modified to allow for a third x variable, calculates the risk score for a borrower. \ndef linear_score(w, x0, x1, x2):\n    return w[0]*x0 + w[1]*x1 + w[2]*x2\n\n\n#Predict makes binary predictions for data using a supplied score function with weights w and a supplied threshold. Taken from lecture notes from week 2.\n#We begin with a 0 threshold but later on test others to find an optimal threshold\n\nt = 0\n\ndef predict(score_fun, w, threshold, df):\n    \"\"\"\n    make binary predictions for data df using a supplied score function with weights w and supplied threshold. \n    \"\"\"\n    scores = score_fun(w, df[\"person_income\"], df[\"loan_amnt\"], df[\"person_emp_length\"])\n    return 1*(scores &gt; threshold)\n\ndf_train[\"decision\"] = predict(linear_score, LR.coef_[0], t, df_train)\n(df_train[\"decision\"] == df_train[\"loan_status\"]).mean()\n\n0.8080062862880342\n\n\n\n# Creating a funciton to find profit\n#The loan_int_rate variable is expressed as a percentage, so we divide it by 100 to make it a regular proportion instead in both helper variables\n\n#Helper function to calculate profit for when loans are repaid, using the provided formula\ndef calculateGain(loan_amnt, loan_int_rate):\n    return np.sum(loan_amnt*(1 + 0.25*loan_int_rate/100)**10 - loan_amnt) \n\n#Helper function to calculate loss for when loans are defaulted on, using the provided formula\ndef calculateLoss(loan_amnt, loan_int_rate):\n    return np.sum(loan_amnt*(1 + 0.25*loan_int_rate/100)**3 - 1.7*loan_amnt)\n    \ndef find_profit(df):\n    #Below df_repaid and df_default are created to select only the data points the model chooses\n    df_repaid = df[df[\"loan_status\"] == 0]\n    df_repaid = df_repaid[df_repaid[\"decision\"] == 0]\n    df_default = df[df[\"loan_status\"] == 1]\n    df_default = df_default[df_default[\"decision\"] == 0]\n    \n    return calculateGain(df_repaid[\"loan_amnt\"], df_repaid[\"loan_int_rate\"]) + calculateLoss(df_default[\"loan_amnt\"], df_default[\"loan_int_rate\"])\n\nfind_profit(df_train)\n\n25068803.47746343\n\n\nThe below code runs find_profit on every integer from -100 to 100 to try to find the threshold that gets us the highest profit. We find that a threshold of -1 corresponds to the highest profit value, which is about $25 million. To find this threshold, we use the idxmax() function, which gets us the first occurance of a maximum over an axis. In this case, it helps us find whatever threshold corresponds to the highest profit.\n\niterations = 200\npredictions = []\nfor i in range(iterations):\n    threshold = (-iterations/2)+(i)\n    df_train[\"decision\"] = predict(linear_score, LR.coef_[0], threshold, df_train)\n    predictions.append((threshold, find_profit(df_train)))\n\n\npredictions_df = pd.DataFrame(data=predictions)\npredictions_df.columns =['Threshold', 'Profit']\n\nsns.relplot(data=predictions_df, x=\"Threshold\", y=\"Profit\")\npredictions_df['Threshold'][predictions_df['Profit'].idxmax()], predictions_df['Profit'].max()\n\n\n\n\n\n\n\n\nWe obtain from our output above the chart (-1.0, 25755817.698476546) that the profit-maximizing threshold is -1.\n\n\n\n\n#In these code block, we find for the training set the total profit of our model, the profit per approved borrower, and the accuracy rate.\nfinal_threshold = -1\n\ndf_train[\"decision\"] = predict(linear_score, LR.coef_[0], final_threshold, df_train)\nborrowers_count = df_train[df_train[\"decision\"]==0].count()[\"loan_int_rate\"]\nfind_profit(df_train), find_profit(df_train)/borrowers_count, (df_train[\"decision\"] == df_train[\"loan_status\"]).mean()\n\n(25755817.698476546, 1819.0421426990993, 0.6927576723272362)\n\n\n\n#In these code block, we find for the test set the total profit of our model, the profit per approved borrower, and the accuracy rate.\nurl = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/credit-risk/test.csv\"\ndf_test = pd.read_csv(url)\n\ndf_test[\"decision\"] = predict(linear_score, LR.coef_[0], final_threshold, df_test)\nborrowers_count = df_test[df_test[\"decision\"]==0].count()[\"loan_int_rate\"]\nfind_profit(df_test), find_profit(df_test)/borrowers_count, (df_test[\"decision\"] == df_test[\"loan_status\"]).mean()\n\n(5965836.794978274, 1632.2398891869423, 0.6898879852692957)\n\n\nWhat is the expected profit per borrower on the test set? Is it similar to your profit on the training set?\nThe profit per borrower was lower in the test dataset ($1,632) than the training dataset ($1,819), but the accuracy was similar, where accuracy is defined as the % of the time our default prediction actually matched the borrower’s default status.\nTraining accuracy: 69.3%\nTesting accuracy: 69.0%\n\n\n\n\ndf_test.groupby([\"loan_intent\"])[[\"loan_status\", \"decision\"]].mean(numeric_only=True)\n\n\n\n\n\n\n\n\n\nloan_status\ndecision\n\n\nloan_intent\n\n\n\n\n\n\nDEBTCONSOLIDATION\n0.279497\n0.386847\n\n\nEDUCATION\n0.167421\n0.401961\n\n\nHOMEIMPROVEMENT\n0.246088\n0.270270\n\n\nMEDICAL\n0.281553\n0.406958\n\n\nPERSONAL\n0.219227\n0.385445\n\n\nVENTURE\n0.145701\n0.361086\n\n\n\n\n\n\n\n\nThe above table shows us the default rates by loan category, as well as what proportion of borrowers were approved by our model. Medical loans have the highest rejection rates and the highest default rates.\n\ndf_test.groupby([\"decision\"]).mean(numeric_only=True)\n\n\n\n\n\n\n\n\n\nperson_age\nperson_income\nperson_emp_length\nloan_amnt\nloan_int_rate\nloan_status\nloan_percent_income\ncb_person_cred_hist_length\n\n\ndecision\n\n\n\n\n\n\n\n\n\n\n\n\n0\n28.064977\n82754.051932\n5.244782\n8949.870785\n10.709193\n0.123554\n0.115412\n6.052670\n\n\n1\n27.189894\n39522.220049\n4.133252\n10859.555827\n11.528797\n0.381011\n0.263394\n5.496333\n\n\n\n\n\n\n\n\nThe above table shows us the different average statistics of approved vs. rejected borrowers. Approved borrowers tend to be slightly older, have much higher income, have longer employment histories, ask for smaller loans, ask for loans that represent a smaller proportion of their income, and have longer credit histories.\n\nbins = np.array([1,20,40,60,80,100])\ndf_test[\"person_age\"] = pd.cut(df_test[\"person_age\"].astype('Int64'), bins, include_lowest=True)\n\n\ng = sns.barplot(data=df_test, x=\"person_age\", y=\"decision\", color='blue')\ng.set(xlabel=\"Person Age Range\", ylabel=\"% of Age Range Rejected (w/ Confidence Intervals)\")\nplt.show(g)\n\n\n\n\n\n\n\n\nThe above table shows the average decision rating for each age range (bucketed by 20 years). The Y axis shows what % of the age range is rejected. The lines on the bars indicate 95% confidence intervals.\nQuestions: 1. Is it more difficult for people in certain age groups to access credit under your proposed system? 2. Is it more difficult for people to get loans in order to pay for medical expenses? 2a. How does this compare with the actual rate of default in that group? 2b. What about people seeking loans for business ventures or education? 3. How does a person’s income level impact the ease with which they can access credit under your decision system?\nResponse:\nFor the purpose of this discussion, we will consider a loan “rejected” if the model deems the loan too-high risk. All statistics are based on the test dataset.\n\nWhile the 20-40 and 40-60 age ranges seem to have about the same access to credit, the 60-80 age group has a significantly higher chance of being rejected–i.e., have lower access to credit. Younger borrowers seem to have the greatest variability in access to credit but generally have high access\nCompared to loans for other purposes, loans for medical expenses are frequently considered too high-risk to make according to our model. Our model is, in a sense, generous: 28.2% of medical borrowers defaulted, but 40.7% were considered too high-risk. In contrast, business venture loans were denied 36.1% of the time with 14.6% risk of default, so the default rate and rejection rate were even further apart. For loans for education, 40.2% of borrowers were rejected, while 16.7% of borrowers actually defaulted. So even though a 40.7% rejection rate for medical borrowers is higher than loans for other purposes, the rejection rate seems reasonable when we consider the high default rate of medical loans.\nThe higher the income, the lower the perceived risk by the model. This is clearest in the simple table above that groups individuals by the “decision” column results. The borrowers the model would accept have about 13 more months of work experience, request loans that are smaller by about $2,000, and have credit histories that are 6 months longer. But the starkest differences are in the income of the borrower and (2) the percentage of income the loan represented, which is directly related to income. The income of approved borrowers is about double the income of rejected borrowers. The loan-to-income ratio is about three times higher for rejected borrowers than approved borrowers.\n\n\n\n\nDiscussion on Fairness\nConsidering that people seeking loans for medical expense have high rates of default, is it fair that it is more difficult for them to obtain access to credit?\nFairness\nFairness in decision-making is to make choices that minimize harm to all parties, with particular regard to parties with low/no control.\nControl\nThe bank has full control over whether to make the loan, so they clearly have substantial control. The borrower has far less control but not no control–excluding cases in which people have a serious illness / injury that prevents them from working, they have some level of control over their personal finances, particularly their income. Still, the borrower has likely little control over the size of the loan they need given the nature of medical expenses and, relatedly, the percentage of income their loan constitutes. So in this way, it’s unlikely that a perfectly fair decision can be made. But the bank has to make a decision, and so the goal should be to achieve a target that gets as close to fairness as possible.\nHarm\nIt is not only the borrower who can experience harm in this scenario by being denied a loan. The bank experiences financial harm by lending to a borrower with excessively high risk. This harm is harder to see immediately–it’s distributed in the form of risk or loss across shareholders, management, employees, depositors, lenders, etc, but it’s harm nonetheless. And if a bank were to repeatedly make loans with negative expected value, it risks serious harm to those stakeholders (e.g., people losing savings in the bank’s stock; employees losing jobs; depositors losing uninsured deposits).\nIt’s possible the bank could just make loans with lower expected value instead, not negative expected value. But even that could mean a decline in the business over time as competitors generate greater profits and reinvest those profits to become more competitive, harming this bank’s business and hence its stakeholders.\nIn conclusion, balancing the benefit to the bank’s stakeholders with the potential harm to rejected borrowers, I conclude that it is fair for medical loan borrowers to have more difficulty accessing credit.\nTo reach a conclusion about whether this specific model and its decisions are fair, we would have to make assumptions about the level of harm being done to rejected borrowers and the benefit to stakeholders in the bank from those borrowers being rejected.\nReflection on Blog Post\nI found that it is possible to construct a logistic regression model that can predict borrower outcomes with relative accuracy. One of the most interesting findings was that in this case, to maximize our target variable, we actually didn’t optimize accuracy. A threshold of 0 yields around 80% accuracy on the training set, far higher than our profit-maximizing threshold of -1, which yields 69% accuracy on the training set. I learned more about how to visualize data and had to grapple with the best ways to visualize so many variables. I ultimately concluded that I would keep my graphs relatively simple and show a more complete story via tables. I learned to work with subsets of my own data: Part D in particular was tricky for me because I had trouble finding a way to construct the find_profit function.\nUnlike the Classifying Penguins post, there was a lot less guidance, which I think was helpful in forcing me to edit and therefore engage further with the example code given previously (e.g., pre-processing the data at the start of Part C)"
  },
  {
    "objectID": "posts/classifying-penguins/ClassifyingPenguins.html",
    "href": "posts/classifying-penguins/ClassifyingPenguins.html",
    "title": "Classifying Penguins",
    "section": "",
    "text": "Blog Post 1: Classifying Palmer Penguins\nAbstract:\nThis post seeks to identify what qualitative and quantative features we should select to achieve a 100% accuracy rate using a machine learning model (specifically a logistic regression model) to predict a penguin’s species. We exhaustively test combinations of available features to find the combination that leads to the highest accuracy on training data. The features found to lead to a model with 100% accuracy on the test dataset were the island a penguin was on, the penguins’ culmen length, and their culmen depth.\nI have neither given nor received unauthorized aid on this assignment - James Ohr\n\nimport pandas as pd\n\ntrain_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/train.csv\"\ntrain = pd.read_csv(train_url)\n\n\ntrain.head()\n\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\n\n\n0\nPAL0809\n31\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN63A1\nYes\n11/24/08\n40.9\n16.6\n187.0\n3200.0\nFEMALE\n9.08458\n-24.54903\nNaN\n\n\n1\nPAL0809\n41\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN74A1\nYes\n11/24/08\n49.0\n19.5\n210.0\n3950.0\nMALE\n9.53262\n-24.66867\nNaN\n\n\n2\nPAL0708\n4\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN32A2\nYes\n11/27/07\n50.0\n15.2\n218.0\n5700.0\nMALE\n8.25540\n-25.40075\nNaN\n\n\n3\nPAL0708\n15\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN38A1\nYes\n12/3/07\n45.8\n14.6\n210.0\n4200.0\nFEMALE\n7.79958\n-25.62618\nNaN\n\n\n4\nPAL0809\n34\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN65A2\nYes\n11/24/08\n51.0\n18.8\n203.0\n4100.0\nMALE\n9.23196\n-24.17282\nNaN\n\n\n\n\n\n\n\n\nThe below code preprocesses the data: it assigns a unique numerical value to each unique category in the “Species” column, removes variables that are not of interest, removes observations where the value for “Sex” is “.”, and removes any observations with missing variable values.\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nle.fit(train[\"Species\"])\n\ndef prepare_data(df):\n  df = df.drop([\"studyName\", \"Sample Number\", \"Individual ID\", \"Date Egg\", \"Comments\", \"Region\"], axis = 1)\n  df = df[df[\"Sex\"] != \".\"]\n  df = df.dropna()\n  y = le.transform(df[\"Species\"])\n  df = df.drop([\"Species\"], axis = 1)\n  df = pd.get_dummies(df)\n  return df, y\n\nX_train, y_train = prepare_data(train)\n\nX_train.head()\n\n\n\n\n\n\n\n\n\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nIsland_Biscoe\nIsland_Dream\nIsland_Torgersen\nStage_Adult, 1 Egg Stage\nClutch Completion_No\nClutch Completion_Yes\nSex_FEMALE\nSex_MALE\n\n\n\n\n0\n40.9\n16.6\n187.0\n3200.0\n9.08458\n-24.54903\n0\n1\n0\n1\n0\n1\n1\n0\n\n\n1\n49.0\n19.5\n210.0\n3950.0\n9.53262\n-24.66867\n0\n1\n0\n1\n0\n1\n0\n1\n\n\n2\n50.0\n15.2\n218.0\n5700.0\n8.25540\n-25.40075\n1\n0\n0\n1\n0\n1\n0\n1\n\n\n3\n45.8\n14.6\n210.0\n4200.0\n7.79958\n-25.62618\n1\n0\n0\n1\n0\n1\n1\n0\n\n\n4\n51.0\n18.8\n203.0\n4100.0\n9.23196\n-24.17282\n0\n1\n0\n1\n0\n1\n0\n1\n\n\n\n\n\n\n\n\n\nimport seaborn as sns\n#Creates a table showing means by island\ntrain.groupby([\"Island\", \"Species\"]).aggregate('mean')\n\nC:\\Users\\james\\AppData\\Local\\Temp\\ipykernel_33480\\3605326083.py:3: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n  train.groupby([\"Island\", \"Species\"]).aggregate('mean')\n\n\n\n\n\n\n\n\n\n\n\nSample Number\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\n\n\nIsland\nSpecies\n\n\n\n\n\n\n\n\n\n\n\nBiscoe\nAdelie Penguin (Pygoscelis adeliae)\n66.030303\n38.845455\n18.475758\n188.636364\n3711.363636\n8.788643\n-25.920138\n\n\nGentoo penguin (Pygoscelis papua)\n60.244898\n47.073196\n14.914433\n216.752577\n5039.948454\n8.247341\n-26.149389\n\n\nDream\nAdelie Penguin (Pygoscelis adeliae)\n90.622222\n38.826667\n18.306667\n190.133333\n3728.888889\n8.933945\n-25.769529\n\n\nChinstrap penguin (Pygoscelis antarctica)\n35.631579\n48.826316\n18.366667\n196.000000\n3743.421053\n9.331004\n-24.553401\n\n\nTorgersen\nAdelie Penguin (Pygoscelis adeliae)\n67.547619\n39.229268\n18.468293\n191.195122\n3712.804878\n8.846768\n-25.715095\n\n\n\n\n\n\n\n\nThe above table shows that each island has a different combination of penguin species. It’s worth nothing that within each island, the different penguin species seem to have notable differences in culmen length and flipper length. The only island on which body mass and culmen depth distinguish its two species of resident penguins is Biscoe.\n\n#Creates a scatterplot whose axes are culmen depth and body mass, with points colored by species\nsns.scatterplot(data=train, x=\"Culmen Depth (mm)\", y=\"Body Mass (g)\", hue=\"Species\")\n\n\n\n\n\n\n\n\nThe above figure shows that there’s a clear divide between Gentoo penguins and the other two penguin species in body mass–Gentoo penguins are heavier regardless of culmen depth. But controlling for the species, there’s a clear positive linear relationship between body mass and culmen depth. Adelie and Chinstrap penguins seem to have the same linear relationship between body mass and culmen depth.\n\n#Creates a scatterplot whose axes are flipper length and body mass, with points colored by island\nsns.scatterplot(data=train, x=\"Flipper Length (mm)\", y=\"Body Mass (g)\", hue=\"Island\")\n\n\n\n\n\n\n\n\nThe above figure shows that regardless of the island a penguin is from, there’s a linear relationship between body mass and flipper length. But while penguins on Biscoe seem to have a greater range of body mass and flipper length, whereas penguins on Dream and Torgersen occupy a similar, tighter range.\nTraining the Model\nNow we choose three features of the data to achieve 100% testing accuracy. To do so, we use a nested for-loop to construct every possible combination of 1 qualitative feature and 2 quantitative features to use in training a logistic regression model. The outer for-loop sets a qualitative variable to use. The inner for-loop take a pair of quantitative variables from the all_quant_cols array.\nIncluded in the inner loop is an if-statement that ensures we keep track of the features that lead to the highest score. Those features are stored in the best_cols variable.\n\nfrom itertools import combinations\nfrom sklearn.linear_model import LogisticRegression\nbest_cols = [] #keeps track of the best features to use\nmax_score = 0 #keeps track of highest score so far\n\nall_qual_cols = ['Clutch Completion', 'Island']\nall_quant_cols = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Flipper Length (mm)', 'Body Mass (g)']\nLR = LogisticRegression(max_iter=10000)\nfor qual in all_qual_cols: \n  qual_cols = [col for col in X_train.columns if qual in col ]\n  for pair in combinations(all_quant_cols, 2):\n    cols = qual_cols + list(pair)\n    LR.fit(X_train[cols], y_train)\n    print(cols)\n    print(LR.score(X_train[cols], y_train))\n    if LR.score(X_train[cols], y_train) &gt; max_score:\n      max_score = LR.score(X_train[cols], y_train)\n      best_cols = cols\n\nLR.fit(X_train[best_cols], y_train)\n\n['Clutch Completion_No', 'Clutch Completion_Yes', 'Culmen Length (mm)', 'Culmen Depth (mm)']\n0.96484375\n['Clutch Completion_No', 'Clutch Completion_Yes', 'Culmen Length (mm)', 'Flipper Length (mm)']\n0.95703125\n['Clutch Completion_No', 'Clutch Completion_Yes', 'Culmen Length (mm)', 'Body Mass (g)']\n0.9453125\n['Clutch Completion_No', 'Clutch Completion_Yes', 'Culmen Depth (mm)', 'Flipper Length (mm)']\n0.81640625\n['Clutch Completion_No', 'Clutch Completion_Yes', 'Culmen Depth (mm)', 'Body Mass (g)']\n0.76953125\n['Clutch Completion_No', 'Clutch Completion_Yes', 'Flipper Length (mm)', 'Body Mass (g)']\n0.63671875\n['Island_Biscoe', 'Island_Dream', 'Island_Torgersen', 'Culmen Length (mm)', 'Culmen Depth (mm)']\n0.99609375\n['Island_Biscoe', 'Island_Dream', 'Island_Torgersen', 'Culmen Length (mm)', 'Flipper Length (mm)']\n0.9765625\n['Island_Biscoe', 'Island_Dream', 'Island_Torgersen', 'Culmen Length (mm)', 'Body Mass (g)']\n0.9765625\n['Island_Biscoe', 'Island_Dream', 'Island_Torgersen', 'Culmen Depth (mm)', 'Flipper Length (mm)']\n0.8828125\n['Island_Biscoe', 'Island_Dream', 'Island_Torgersen', 'Culmen Depth (mm)', 'Body Mass (g)']\n0.8359375\n['Island_Biscoe', 'Island_Dream', 'Island_Torgersen', 'Flipper Length (mm)', 'Body Mass (g)']\n0.75390625\n\n\nLogisticRegression(max_iter=10000)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LogisticRegressionLogisticRegression(max_iter=10000)\n\n\nCross-Validation\nThe below code uses a scikit-learn method to calculate cross-validation scores with five folds. The results are largely promising, with the lowest accuracy rate being 96%.\n\nfrom sklearn.model_selection import cross_val_score\n\ncv_scores_LR = cross_val_score(LR, X_train[best_cols], y_train, cv=5)\ncv_scores_LR\n\narray([0.98076923, 1.        , 1.        , 0.96078431, 1.        ])\n\n\nTesting\nThe below code loads test.csv, preprocesses the data with prepare_data, and scores the LR on the test data. The result is 100% accuracy.\n\ntest_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/test.csv\"\ntest = pd.read_csv(test_url)\n\nX_test, y_test = prepare_data(test)\nLR.score(X_test[best_cols], y_test)\n\n1.0\n\n\nDecision Regions\n\n#This section of code retrains the model on cols, which has the same features as best_col, just\n#with the columns rearranged so that Matplotlib doesn't return an error later in the next code block.\n\ncols = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Island_Biscoe', 'Island_Dream', 'Island_Torgersen']\nLR = LogisticRegression(max_iter=10000)\nLR.fit(X_train[cols], y_train)\n\nLogisticRegression(max_iter=10000)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LogisticRegressionLogisticRegression(max_iter=10000)\n\n\nThe below code defines a function, plot_regions, that creates multiple charts (the # is determined by how many qualitative variables there are), each with the same axes. The colors of different regions correspond to the species predictions made by the model, whereas the colors of observations correspond to actual species values.\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nfrom matplotlib.patches import Patch\n\ndef plot_regions(model, X, y):\n    \n    x0 = X[X.columns[0]]\n    x1 = X[X.columns[1]]\n    qual_features = X.columns[2:]\n    \n    fig, axarr = plt.subplots(1, len(qual_features), figsize = (7, 3))\n\n    # Creates a grid\n    grid_x = np.linspace(x0.min(),x0.max(),501)\n    grid_y = np.linspace(x1.min(),x1.max(),501)\n    xx, yy = np.meshgrid(grid_x, grid_y)\n    \n    XX = xx.ravel()\n    YY = yy.ravel()\n\n    for i in range(len(qual_features)):\n      XY = pd.DataFrame({\n          X.columns[0] : XX,\n          X.columns[1] : YY\n      })\n\n      for j in qual_features:\n        XY[j] = 0\n\n      XY[qual_features[i]] = 1\n\n      p = model.predict(XY)\n      p = p.reshape(xx.shape)\n      \n      \n      # use contour plot to visualize the predictions\n      axarr[i].contourf(xx, yy, p, cmap = \"jet\", alpha = 0.2, vmin = 0, vmax = 2)\n      \n      ix = X[qual_features[i]] == 1\n      # plot the data\n      axarr[i].scatter(x0[ix], x1[ix], c = y[ix], cmap = \"jet\", vmin = 0, vmax = 2)\n      \n      axarr[i].set(xlabel = X.columns[0], \n            ylabel  = X.columns[1], \n            title = qual_features[i])\n      \n      patches = []\n      for color, spec in zip([\"red\", \"green\", \"blue\"], [\"Adelie\", \"Chinstrap\", \"Gentoo\"]):\n        patches.append(Patch(color = color, label = spec))\n\n      plt.legend(title = \"Species\", handles = patches, loc = \"best\")\n      \n      plt.tight_layout()\n\nplot_regions(LR, X_train[cols], y_train)\n\n\n\n\n\n\n\n\nAbove are the decision regions for the training data. We effectively control for the island a penguin is from to determine their species based on their culmen depth and length. The only inaccurately labeled point is a penguin on Dream with a slightly shorter culmen than its depth and would predict.\n\nplot_regions(LR, X_test[cols], y_test)\n\n\n\n\n\n\n\n\nOur 100% accuracy is reflected here–every plotted observation is correctly categorized into the region with the corresponding color.\nConfusion Matrix\nBelow is code to create a confusion matrix for our results. Given that there were no false positives or false negatives, we see a confusion matrix with non-zeros only on the diagonal.\n\nfrom sklearn.metrics import confusion_matrix\n\ny_test_pred = LR.predict(X_test[cols])\nC = confusion_matrix(y_test, y_test_pred)\nC\n\narray([[31,  0,  0],\n       [ 0, 11,  0],\n       [ 0,  0, 26]], dtype=int64)\n\n\nDiscussion\nIn this post, we found that, with a logistic regression model, the qualitative feature “Island” combined with culmen depth and culmen length can predict with great accuracy (100% accuracy on our test data) whether the penguin is of the Adelie, Chinstrap, or Gentoo species.\nThe original figures I created earlier in the post actually weren’t helpful in finding the best features. The body mass and flipper length relationship in particular was something that intuitively seemed right to me, but it wasn’t actually useful in helping predict penguin species.\nThrough this blog post, I’ve learned some basic features of scikit-learn, seaborn, Pandas, and Matplotlib. I’m not sure if I’m just not sufficiently comfortable with Matplotlib, but it gave me more trouble than the rest of the entire project. I had to re-train the model on a re-arranged set of column names (instead of best_cols) just to get it to stop giving me the same error. The most valuable aspect of it, I think, was just getting a better hang of the syntax and gaining familiarity with the tools we use in the class, especially scikit-learn."
  },
  {
    "objectID": "posts/decision-making/DecisionMaking.html#part-a-grab-the-data",
    "href": "posts/decision-making/DecisionMaking.html#part-a-grab-the-data",
    "title": "Decision Making",
    "section": "",
    "text": "#Importing the data and storing it in variable df_train\n\nimport pandas as pd\nurl = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/credit-risk/train.csv\"\ndf_train = pd.read_csv(url)"
  },
  {
    "objectID": "posts/decision-making/DecisionMaking.html#part-b-explore-the-data",
    "href": "posts/decision-making/DecisionMaking.html#part-b-explore-the-data",
    "title": "Decision Making",
    "section": "",
    "text": "df_train.head()\n\n\n\n\n\n\n\n\n\nperson_age\nperson_income\nperson_home_ownership\nperson_emp_length\nloan_intent\nloan_grade\nloan_amnt\nloan_int_rate\nloan_status\nloan_percent_income\ncb_person_default_on_file\ncb_person_cred_hist_length\n\n\n\n\n0\n25\n43200\nRENT\nNaN\nVENTURE\nB\n1200\n9.91\n0\n0.03\nN\n4\n\n\n1\n27\n98000\nRENT\n3.0\nEDUCATION\nC\n11750\n13.47\n0\n0.12\nY\n6\n\n\n2\n22\n36996\nRENT\n5.0\nEDUCATION\nA\n10000\n7.51\n0\n0.27\nN\n4\n\n\n3\n24\n26000\nRENT\n2.0\nMEDICAL\nC\n1325\n12.87\n1\n0.05\nN\n4\n\n\n4\n29\n53004\nMORTGAGE\n2.0\nHOMEIMPROVEMENT\nA\n15000\n9.63\n0\n0.28\nN\n10\n\n\n\n\n\n\n\n\nThe above table helps me get a sense of the variables in the dataset and their types.\n\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\ng = sns.displot(df_train, x=\"loan_percent_income\", hue=\"loan_status\", element=\"step\", legend=False)\nplt.legend(title='Loan Status', loc='upper right', labels=['Default', 'No Default'])\ng.set(xlabel=\"Loan Proportion of Income\")\nplt.show(g)\n\n\n\n\n\n\n\n\nThe above figure shows that there are * significantly more borrowers who didn’t default than those who did * individuals who receive a loan less than 30% of their income are unlikely to default on their loan * individuals who receive a loan over 30% of their income are significantly more likely to default than not.\n\ng = sns.displot(df_train, x=\"loan_int_rate\", hue=\"loan_intent\", kind=\"kde\")\ng.legend.set_title(\"Loan Purpose\")\ng.set(xlabel=\"Loan Interest Rate (%)\")\nplt.show(g)\n\n\n\n\n\n\n\n\nThe above figure shows an interesting pattern across every single type of loan. Each distribution is approximately bimodal (although some have three local maxima). It’s unsurprising, but there are far more people under the second peak, i.e., the higher interest rate peak, for each type of loan.\n\ndf_train.groupby(\"loan_intent\").mean(numeric_only=True)\n\n\n\n\n\n\n\n\n\nperson_age\nperson_income\nperson_emp_length\nloan_amnt\nloan_int_rate\nloan_status\nloan_percent_income\ncb_person_cred_hist_length\n\n\nloan_intent\n\n\n\n\n\n\n\n\n\n\n\n\nDEBTCONSOLIDATION\n27.588798\n66693.453327\n4.759419\n9620.901149\n10.983305\n0.287458\n0.170869\n5.695548\n\n\nEDUCATION\n26.597620\n63847.711917\n4.440192\n9460.015604\n10.965465\n0.173396\n0.169352\n5.141603\n\n\nHOMEIMPROVEMENT\n28.981737\n73082.079600\n5.103754\n10348.725017\n11.160075\n0.264645\n0.166733\n6.430048\n\n\nMEDICAL\n27.950982\n61314.583868\n4.782062\n9242.269907\n11.051946\n0.263289\n0.172825\n5.913547\n\n\nPERSONAL\n28.288339\n68070.502495\n4.897997\n9549.427178\n11.009814\n0.193739\n0.168671\n6.151316\n\n\nVENTURE\n27.588643\n66098.818162\n4.877869\n9516.417425\n10.940866\n0.148678\n0.170130\n5.744040\n\n\n\n\n\n\n\n\nBorrowers intending to use loans for home improvement tend to: * have higher incomes * receive greater loans * tend to have higher default rates, which are in line with default rates of loans for medical and debt consolidation.\nMedical loan borrowers tend to have the lowest incomes, the highest loan-to-income ratios, and the lowest loan amounts. The first observation is most surprising–I would have expected education loan borrowers to have the lowest incomes (maybe this has to do with co-signers)."
  },
  {
    "objectID": "posts/decision-making/DecisionMaking.html#part-c-build-a-model",
    "href": "posts/decision-making/DecisionMaking.html#part-c-build-a-model",
    "title": "Decision Making",
    "section": "",
    "text": "The below code pre-processes our data for use in the model. We drop the “loan_grade” variable, which the instructions disallow for building th emodel. We separate out “loan status” into an outcome variable, y. We transform categorical variables from strings into numbers.\n\n#Data pre-processing\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\n\ndef prepare_data(df):\n  df = df_train.drop([\"loan_grade\"], axis = 1)\n  df = df.dropna()\n  le.fit(df_train[\"person_home_ownership\"])\n  df[\"person_home_ownership\"] = le.transform(df[\"person_home_ownership\"])\n  le.fit(df_train[\"loan_intent\"])\n  df[\"loan_intent\"] = le.transform(df[\"loan_intent\"])\n  y = df[\"loan_status\"]\n  df = df.drop([\"loan_status\"], axis = 1)\n  df = pd.get_dummies(df)\n  return df, y\n\nX_train, y_train = prepare_data(df_train)\ndf_train = df_train.dropna()\n\nBelow, I chose the features for the model and fitted our model to our training data. I chose income and loan amount because they’re the two components of the loan-to-income ratio, which seemed to be relatively revealing in the above chart showing loan status vs. loan-to-income. Adding employment length didn’t actually change the accuracy of the model, but I added it just because intuitively I thought it might have an impact even though the table above didn’t show anything particularly interesting regarding the variable.\n\n#Choosing features\nfrom sklearn.linear_model import LogisticRegression\n\nLR = LogisticRegression()\n\ncols = [\"person_income\", \"loan_amnt\", \"person_emp_length\"]\n\nLR.fit(X_train[cols], y_train)\nLR.score(X_train[cols], y_train)\nLR.coef_[0]\n\narray([-4.05735465e-05,  1.06559046e-04, -2.48736069e-08])"
  },
  {
    "objectID": "posts/decision-making/DecisionMaking.html#part-d-find-a-threshold",
    "href": "posts/decision-making/DecisionMaking.html#part-d-find-a-threshold",
    "title": "Decision Making",
    "section": "",
    "text": "Below we have code that (1) finds the profit the bank makes from all of its loans (we ignore any NAs) and (2) identifies the threshold that maximizes profit.\n\n#This function, taken from the week 2 lecture notes and just slightly modified to allow for a third x variable, calculates the risk score for a borrower. \ndef linear_score(w, x0, x1, x2):\n    return w[0]*x0 + w[1]*x1 + w[2]*x2\n\n\n#Predict makes binary predictions for data using a supplied score function with weights w and a supplied threshold. Taken from lecture notes from week 2.\n#We begin with a 0 threshold but later on test others to find an optimal threshold\n\nt = 0\n\ndef predict(score_fun, w, threshold, df):\n    \"\"\"\n    make binary predictions for data df using a supplied score function with weights w and supplied threshold. \n    \"\"\"\n    scores = score_fun(w, df[\"person_income\"], df[\"loan_amnt\"], df[\"person_emp_length\"])\n    return 1*(scores &gt; threshold)\n\ndf_train[\"decision\"] = predict(linear_score, LR.coef_[0], t, df_train)\n(df_train[\"decision\"] == df_train[\"loan_status\"]).mean()\n\n0.8080062862880342\n\n\n\n# Creating a funciton to find profit\n#The loan_int_rate variable is expressed as a percentage, so we divide it by 100 to make it a regular proportion instead in both helper variables\n\n#Helper function to calculate profit for when loans are repaid, using the provided formula\ndef calculateGain(loan_amnt, loan_int_rate):\n    return np.sum(loan_amnt*(1 + 0.25*loan_int_rate/100)**10 - loan_amnt) \n\n#Helper function to calculate loss for when loans are defaulted on, using the provided formula\ndef calculateLoss(loan_amnt, loan_int_rate):\n    return np.sum(loan_amnt*(1 + 0.25*loan_int_rate/100)**3 - 1.7*loan_amnt)\n    \ndef find_profit(df):\n    #Below df_repaid and df_default are created to select only the data points the model chooses\n    df_repaid = df[df[\"loan_status\"] == 0]\n    df_repaid = df_repaid[df_repaid[\"decision\"] == 0]\n    df_default = df[df[\"loan_status\"] == 1]\n    df_default = df_default[df_default[\"decision\"] == 0]\n    \n    return calculateGain(df_repaid[\"loan_amnt\"], df_repaid[\"loan_int_rate\"]) + calculateLoss(df_default[\"loan_amnt\"], df_default[\"loan_int_rate\"])\n\nfind_profit(df_train)\n\n25068803.47746343\n\n\nThe below code runs find_profit on every integer from -100 to 100 to try to find the threshold that gets us the highest profit. We find that a threshold of -1 corresponds to the highest profit value, which is about $25 million. To find this threshold, we use the idxmax() function, which gets us the first occurance of a maximum over an axis. In this case, it helps us find whatever threshold corresponds to the highest profit.\n\niterations = 200\npredictions = []\nfor i in range(iterations):\n    threshold = (-iterations/2)+(i)\n    df_train[\"decision\"] = predict(linear_score, LR.coef_[0], threshold, df_train)\n    predictions.append((threshold, find_profit(df_train)))\n\n\npredictions_df = pd.DataFrame(data=predictions)\npredictions_df.columns =['Threshold', 'Profit']\n\nsns.relplot(data=predictions_df, x=\"Threshold\", y=\"Profit\")\npredictions_df['Threshold'][predictions_df['Profit'].idxmax()], predictions_df['Profit'].max()\n\n\n\n\n\n\n\n\nWe obtain from our output above the chart (-1.0, 25755817.698476546) that the profit-maximizing threshold is -1."
  },
  {
    "objectID": "posts/decision-making/DecisionMaking.html#part-e-evaluate-your-model-from-the-banks-perspective",
    "href": "posts/decision-making/DecisionMaking.html#part-e-evaluate-your-model-from-the-banks-perspective",
    "title": "Decision Making",
    "section": "",
    "text": "#In these code block, we find for the training set the total profit of our model, the profit per approved borrower, and the accuracy rate.\nfinal_threshold = -1\n\ndf_train[\"decision\"] = predict(linear_score, LR.coef_[0], final_threshold, df_train)\nborrowers_count = df_train[df_train[\"decision\"]==0].count()[\"loan_int_rate\"]\nfind_profit(df_train), find_profit(df_train)/borrowers_count, (df_train[\"decision\"] == df_train[\"loan_status\"]).mean()\n\n(25755817.698476546, 1819.0421426990993, 0.6927576723272362)\n\n\n\n#In these code block, we find for the test set the total profit of our model, the profit per approved borrower, and the accuracy rate.\nurl = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/credit-risk/test.csv\"\ndf_test = pd.read_csv(url)\n\ndf_test[\"decision\"] = predict(linear_score, LR.coef_[0], final_threshold, df_test)\nborrowers_count = df_test[df_test[\"decision\"]==0].count()[\"loan_int_rate\"]\nfind_profit(df_test), find_profit(df_test)/borrowers_count, (df_test[\"decision\"] == df_test[\"loan_status\"]).mean()\n\n(5965836.794978274, 1632.2398891869423, 0.6898879852692957)\n\n\nWhat is the expected profit per borrower on the test set? Is it similar to your profit on the training set?\nThe profit per borrower was lower in the test dataset ($1,632) than the training dataset ($1,819), but the accuracy was similar, where accuracy is defined as the % of the time our default prediction actually matched the borrower’s default status.\nTraining accuracy: 69.3%\nTesting accuracy: 69.0%"
  },
  {
    "objectID": "posts/decision-making/DecisionMaking.html#part-f-evaluate-your-model-from-the-borrowers-perspective",
    "href": "posts/decision-making/DecisionMaking.html#part-f-evaluate-your-model-from-the-borrowers-perspective",
    "title": "Decision Making",
    "section": "",
    "text": "df_test.groupby([\"loan_intent\"])[[\"loan_status\", \"decision\"]].mean(numeric_only=True)\n\n\n\n\n\n\n\n\n\nloan_status\ndecision\n\n\nloan_intent\n\n\n\n\n\n\nDEBTCONSOLIDATION\n0.279497\n0.386847\n\n\nEDUCATION\n0.167421\n0.401961\n\n\nHOMEIMPROVEMENT\n0.246088\n0.270270\n\n\nMEDICAL\n0.281553\n0.406958\n\n\nPERSONAL\n0.219227\n0.385445\n\n\nVENTURE\n0.145701\n0.361086\n\n\n\n\n\n\n\n\nThe above table shows us the default rates by loan category, as well as what proportion of borrowers were approved by our model. Medical loans have the highest rejection rates and the highest default rates.\n\ndf_test.groupby([\"decision\"]).mean(numeric_only=True)\n\n\n\n\n\n\n\n\n\nperson_age\nperson_income\nperson_emp_length\nloan_amnt\nloan_int_rate\nloan_status\nloan_percent_income\ncb_person_cred_hist_length\n\n\ndecision\n\n\n\n\n\n\n\n\n\n\n\n\n0\n28.064977\n82754.051932\n5.244782\n8949.870785\n10.709193\n0.123554\n0.115412\n6.052670\n\n\n1\n27.189894\n39522.220049\n4.133252\n10859.555827\n11.528797\n0.381011\n0.263394\n5.496333\n\n\n\n\n\n\n\n\nThe above table shows us the different average statistics of approved vs. rejected borrowers. Approved borrowers tend to be slightly older, have much higher income, have longer employment histories, ask for smaller loans, ask for loans that represent a smaller proportion of their income, and have longer credit histories.\n\nbins = np.array([1,20,40,60,80,100])\ndf_test[\"person_age\"] = pd.cut(df_test[\"person_age\"].astype('Int64'), bins, include_lowest=True)\n\n\ng = sns.barplot(data=df_test, x=\"person_age\", y=\"decision\", color='blue')\ng.set(xlabel=\"Person Age Range\", ylabel=\"% of Age Range Rejected (w/ Confidence Intervals)\")\nplt.show(g)\n\n\n\n\n\n\n\n\nThe above table shows the average decision rating for each age range (bucketed by 20 years). The Y axis shows what % of the age range is rejected. The lines on the bars indicate 95% confidence intervals.\nQuestions: 1. Is it more difficult for people in certain age groups to access credit under your proposed system? 2. Is it more difficult for people to get loans in order to pay for medical expenses? 2a. How does this compare with the actual rate of default in that group? 2b. What about people seeking loans for business ventures or education? 3. How does a person’s income level impact the ease with which they can access credit under your decision system?\nResponse:\nFor the purpose of this discussion, we will consider a loan “rejected” if the model deems the loan too-high risk. All statistics are based on the test dataset.\n\nWhile the 20-40 and 40-60 age ranges seem to have about the same access to credit, the 60-80 age group has a significantly higher chance of being rejected–i.e., have lower access to credit. Younger borrowers seem to have the greatest variability in access to credit but generally have high access\nCompared to loans for other purposes, loans for medical expenses are frequently considered too high-risk to make according to our model. Our model is, in a sense, generous: 28.2% of medical borrowers defaulted, but 40.7% were considered too high-risk. In contrast, business venture loans were denied 36.1% of the time with 14.6% risk of default, so the default rate and rejection rate were even further apart. For loans for education, 40.2% of borrowers were rejected, while 16.7% of borrowers actually defaulted. So even though a 40.7% rejection rate for medical borrowers is higher than loans for other purposes, the rejection rate seems reasonable when we consider the high default rate of medical loans.\nThe higher the income, the lower the perceived risk by the model. This is clearest in the simple table above that groups individuals by the “decision” column results. The borrowers the model would accept have about 13 more months of work experience, request loans that are smaller by about $2,000, and have credit histories that are 6 months longer. But the starkest differences are in the income of the borrower and (2) the percentage of income the loan represented, which is directly related to income. The income of approved borrowers is about double the income of rejected borrowers. The loan-to-income ratio is about three times higher for rejected borrowers than approved borrowers."
  },
  {
    "objectID": "posts/decision-making/DecisionMaking.html#part-g-write-and-reflect",
    "href": "posts/decision-making/DecisionMaking.html#part-g-write-and-reflect",
    "title": "Decision Making",
    "section": "",
    "text": "Discussion on Fairness\nConsidering that people seeking loans for medical expense have high rates of default, is it fair that it is more difficult for them to obtain access to credit?\nFairness\nFairness in decision-making is to make choices that minimize harm to all parties, with particular regard to parties with low/no control.\nControl\nThe bank has full control over whether to make the loan, so they clearly have substantial control. The borrower has far less control but not no control–excluding cases in which people have a serious illness / injury that prevents them from working, they have some level of control over their personal finances, particularly their income. Still, the borrower has likely little control over the size of the loan they need given the nature of medical expenses and, relatedly, the percentage of income their loan constitutes. So in this way, it’s unlikely that a perfectly fair decision can be made. But the bank has to make a decision, and so the goal should be to achieve a target that gets as close to fairness as possible.\nHarm\nIt is not only the borrower who can experience harm in this scenario by being denied a loan. The bank experiences financial harm by lending to a borrower with excessively high risk. This harm is harder to see immediately–it’s distributed in the form of risk or loss across shareholders, management, employees, depositors, lenders, etc, but it’s harm nonetheless. And if a bank were to repeatedly make loans with negative expected value, it risks serious harm to those stakeholders (e.g., people losing savings in the bank’s stock; employees losing jobs; depositors losing uninsured deposits).\nIt’s possible the bank could just make loans with lower expected value instead, not negative expected value. But even that could mean a decline in the business over time as competitors generate greater profits and reinvest those profits to become more competitive, harming this bank’s business and hence its stakeholders.\nIn conclusion, balancing the benefit to the bank’s stakeholders with the potential harm to rejected borrowers, I conclude that it is fair for medical loan borrowers to have more difficulty accessing credit.\nTo reach a conclusion about whether this specific model and its decisions are fair, we would have to make assumptions about the level of harm being done to rejected borrowers and the benefit to stakeholders in the bank from those borrowers being rejected.\nReflection on Blog Post\nI found that it is possible to construct a logistic regression model that can predict borrower outcomes with relative accuracy. One of the most interesting findings was that in this case, to maximize our target variable, we actually didn’t optimize accuracy. A threshold of 0 yields around 80% accuracy on the training set, far higher than our profit-maximizing threshold of -1, which yields 69% accuracy on the training set. I learned more about how to visualize data and had to grapple with the best ways to visualize so many variables. I ultimately concluded that I would keep my graphs relatively simple and show a more complete story via tables. I learned to work with subsets of my own data: Part D in particular was tricky for me because I had trouble finding a way to construct the find_profit function.\nUnlike the Classifying Penguins post, there was a lot less guidance, which I think was helpful in forcing me to edit and therefore engage further with the example code given previously (e.g., pre-processing the data at the start of Part C)"
  },
  {
    "objectID": "posts/perception-algo/perception-algo.html",
    "href": "posts/perception-algo/perception-algo.html",
    "title": "Implementing the Perceptron Algorithm",
    "section": "",
    "text": "%load_ext autoreload\n%autoreload 2\nfrom perceptron import Perceptron, PerceptronOptimizer\n\n\nimport torch\n\ntorch.manual_seed(1234)\n\ndef perceptron_data(n_points = 300, noise = 0.2):\n    \n    y = torch.arange(n_points) &gt;= int(n_points/2)\n    X = y[:, None] + torch.normal(0.0, noise, size = (n_points,2))\n    X = torch.cat((X, torch.ones((X.shape[0], 1))), 1)\n\n    # convert y from {0, 1} to {-1, 1}\n    y = 2*y - 1\n\n    return X, y\n\nX, y = perceptron_data(n_points = 300, noise = 0.2)\n\n\nimport torch\n\nclass LinearModel:\n\n    def __init__(self):\n        self.w = None \n\n    def score(self, X):\n        \"\"\"\n        Compute the scores for each data point in the feature matrix X. \n        The formula for the ith entry of s is s[i] = &lt;self.w, x[i]&gt;. \n\n        If self.w currently has value None, then it is necessary to first initialize self.w to a random value. \n\n        ARGUMENTS: \n            X, torch.Tensor: the feature matrix. X.size() == (n, p), \n            where n is the number of data points and p is the \n            number of features. This implementation always assumes \n            that the final column of X is a constant column of 1s. \n\n        RETURNS: \n            s torch.Tensor: vector of scores. s.size() = (n,)\n        \"\"\"\n        if self.w is None: \n            self.w = torch.rand((X.size()[1]))\n\n        # your computation here: compute the vector of scores s\n        return self.w @ X\n    \n    def predict(self, X):\n        \"\"\"\n        Compute the predictions for each data point in the feature matrix X. The prediction for the ith data point is either 0 or 1. \n\n        ARGUMENTS: \n            X, torch.Tensor: the feature matrix. X.size() == (n, p), \n            where n is the number of data points and p is the \n            number of features. This implementation always assumes \n            that the final column of X is a constant column of 1s. \n\n        RETURNS: \n            y_hat, torch.Tensor: vector predictions in {0.0, 1.0}. y_hat.size() = (n,)\n        \"\"\"\n        #Find the score\n        #Use threshold to set 0 or 1 for each vector\n        #Return the prediction vectors\n        #maybe use np sum where\n\nclass Perceptron(LinearModel):\n\n    def loss(self, X, y):\n        \"\"\"\n        Compute the misclassification rate. A point i is classified correctly if it holds that s_i*y_i_ &gt; 0, where y_i_ is the *modified label* that has values in {-1, 1} (rather than {0, 1}). \n\n        ARGUMENTS: \n            X, torch.Tensor: the feature matrix. X.size() == (n, p), \n            where n is the number of data points and p is the \n            number of features. This implementation always assumes \n            that the final column of X is a constant column of 1s. \n\n            y, torch.Tensor: the target vector.  y.size() = (n,). The possible labels for y are {0, 1}\n        \n        HINT: In order to use the math formulas in the lecture, you are going to need to construct a modified set of targets and predictions that have entries in {-1, 1} -- otherwise none of the formulas will work right! An easy to to make this conversion is: \n        \n        y_ = 2*y - 1\n        \"\"\"\n\n        # replace with your implementation\n        pass\n\n    def grad(self, X, y):\n        pass \n\nclass PerceptronOptimizer:\n\n    def __init__(self, model):\n        self.model = model \n    \n    def step(self, X, y):\n        \"\"\"\n        Compute one step of the perceptron update using the feature matrix X \n        and target vector y. \n        \"\"\"\n        pass"
  },
  {
    "objectID": "posts/perceptron-algo/perceptron-algo.html",
    "href": "posts/perceptron-algo/perceptron-algo.html",
    "title": "Implementing the Perceptron Algorithm",
    "section": "",
    "text": "In this blog post, I implement and test the perceptron algorithm using randomly generated data. The algorithm attempts to categorize data points but is only able reach a loss of zero if the data is linearly separable. I implement the minibatch perceptron algorithm as well, which computes weight updates using multiple observations at a time. For linearly separable data, I find it’s possible to consistently achieve a loss of 0. For data that is not linearly separable, I don’t achieve a loss of 0 with the minibatch perceptron algorithm (where number of observations = number of points used to update at once) but instead see a leveling out at a loss of around 0.28.\n\n%load_ext autoreload\n%autoreload 2\nfrom perceptron import Perceptron, PerceptronOptimizer\n\nThe autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n\n\n\n\nThe below code, from our warmup, defines a function that generates a matrix and an array of random data.\n\nimport torch\nfrom matplotlib import pyplot as plt\n\ntorch.manual_seed(1234)\n\ndef perceptron_data(n_points = 300, noise = 0.2):\n    \n    y = torch.arange(n_points) &gt;= int(n_points/2)\n    X = y[:, None] + torch.normal(0.0, noise, size = (n_points,2))\n    X = torch.cat((X, torch.ones((X.shape[0], 1))), 1)\n\n    # convert y from {0, 1} to {-1, 1}\n    y = 2*y - 1\n\n    return X, y\n\nX, y = perceptron_data(n_points = 300, noise = 0.2)\n\nThe below code is a quick check to ensure the Perceptron code was written correctly. The output of tensor(True) shows Perceptron is probably fine.\n\np = Perceptron()\ns = p.score(X)\nl = p.loss(X, y)\nprint(l)\nprint(l == 0.5)\n\ntensor(0.5000)\ntensor(True)\n\n\nThe below code is our core training loop as a function. As long as the loss exceeds our loss threshold (which by default is 0), we perform the optimizer’s step function to update the weights and then try again. We only iterate up to our max iterations value, which is 1000 times by default.\nIf our final loss vector (loss_vec) value is 0, our program successfully found a weight vector that linearly separates our data.\n\n# instantiate a model and an optimizer\np = Perceptron() \nopt = PerceptronOptimizer(p)\nloss_vec = []\n\ndef train(X, y, max_iterations = 1000, loss_threshold = 0.0):\n    loss = 1.0\n\n    # for keeping track of loss values and number of iterations\n    j = 0\n    n = X.size()[0]\n\n    while loss &gt; loss_threshold and j &lt; max_iterations: # dangerous -- only terminates if data is linearly separable\n        j += 1\n        loss = p.loss(X, y) \n        loss_vec.append(loss)\n        \n        # pick a random data point\n        i = torch.randint(n, size = (1,))\n        x_i = X[[i],:]\n        y_i = y[i]\n        \n        # perform a perceptron update using the random data point\n        opt.step(x_i, y_i)\n    return loss_vec\n\nloss_vec = train(X,y)\nprint(\"Last Vector: \" + str(loss_vec[len(loss_vec)-1]))\nprint(p.w)\n\nLast Vector: tensor(0.)\ntensor([ 2.5406,  0.9279, -1.8141])\n\n\nThe above output shows the final vector in loss_vec is a 0, showing we managed to find a set of weights that minimize the loss. The weights are shown above below the last vector in loss_vec."
  },
  {
    "objectID": "posts/perceptron-algo/perceptron-algo.html#introduction",
    "href": "posts/perceptron-algo/perceptron-algo.html#introduction",
    "title": "Implementing the Perceptron Algorithm",
    "section": "",
    "text": "In this blog post, I implement and test the perceptron algorithm using randomly generated data. The algorithm attempts to categorize data points but is only able reach a loss of zero if the data is linearly separable. I implement the minibatch perceptron algorithm as well, which computes weight updates using multiple observations at a time. For linearly separable data, I find it’s possible to consistently achieve a loss of 0. For data that is not linearly separable, I don’t achieve a loss of 0 with the minibatch perceptron algorithm (where number of observations = number of points used to update at once) but instead see a leveling out at a loss of around 0.28.\n\n%load_ext autoreload\n%autoreload 2\nfrom perceptron import Perceptron, PerceptronOptimizer\n\nThe autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n\n\n\n\nThe below code, from our warmup, defines a function that generates a matrix and an array of random data.\n\nimport torch\nfrom matplotlib import pyplot as plt\n\ntorch.manual_seed(1234)\n\ndef perceptron_data(n_points = 300, noise = 0.2):\n    \n    y = torch.arange(n_points) &gt;= int(n_points/2)\n    X = y[:, None] + torch.normal(0.0, noise, size = (n_points,2))\n    X = torch.cat((X, torch.ones((X.shape[0], 1))), 1)\n\n    # convert y from {0, 1} to {-1, 1}\n    y = 2*y - 1\n\n    return X, y\n\nX, y = perceptron_data(n_points = 300, noise = 0.2)\n\nThe below code is a quick check to ensure the Perceptron code was written correctly. The output of tensor(True) shows Perceptron is probably fine.\n\np = Perceptron()\ns = p.score(X)\nl = p.loss(X, y)\nprint(l)\nprint(l == 0.5)\n\ntensor(0.5000)\ntensor(True)\n\n\nThe below code is our core training loop as a function. As long as the loss exceeds our loss threshold (which by default is 0), we perform the optimizer’s step function to update the weights and then try again. We only iterate up to our max iterations value, which is 1000 times by default.\nIf our final loss vector (loss_vec) value is 0, our program successfully found a weight vector that linearly separates our data.\n\n# instantiate a model and an optimizer\np = Perceptron() \nopt = PerceptronOptimizer(p)\nloss_vec = []\n\ndef train(X, y, max_iterations = 1000, loss_threshold = 0.0):\n    loss = 1.0\n\n    # for keeping track of loss values and number of iterations\n    j = 0\n    n = X.size()[0]\n\n    while loss &gt; loss_threshold and j &lt; max_iterations: # dangerous -- only terminates if data is linearly separable\n        j += 1\n        loss = p.loss(X, y) \n        loss_vec.append(loss)\n        \n        # pick a random data point\n        i = torch.randint(n, size = (1,))\n        x_i = X[[i],:]\n        y_i = y[i]\n        \n        # perform a perceptron update using the random data point\n        opt.step(x_i, y_i)\n    return loss_vec\n\nloss_vec = train(X,y)\nprint(\"Last Vector: \" + str(loss_vec[len(loss_vec)-1]))\nprint(p.w)\n\nLast Vector: tensor(0.)\ntensor([ 2.5406,  0.9279, -1.8141])\n\n\nThe above output shows the final vector in loss_vec is a 0, showing we managed to find a set of weights that minimize the loss. The weights are shown above below the last vector in loss_vec."
  }
]