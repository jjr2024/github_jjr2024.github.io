[
  {
    "objectID": "posts/perceptron-algo/perceptron-algo.html",
    "href": "posts/perceptron-algo/perceptron-algo.html",
    "title": "Implementing the Perceptron Algorithm",
    "section": "",
    "text": "In this blog post, I implement and test the perceptron algorithm using randomly generated data. The algorithm attempts to categorize data points but is only able reach a loss of zero if the data is linearly separable. I implement the minibatch perceptron algorithm as well, which computes weight updates using multiple observations at a time. For linearly separable data, I find it’s possible to consistently achieve a loss of 0. For data that is not linearly separable, I don’t achieve a loss of 0 with the minibatch perceptron algorithm (where number of observations = number of points used to update at once) but instead see a leveling out at a loss of around 0.28.\nLink to Perceptron Python Code: https://github.com/jjr2024/github_jjr2024.github.io/blob/main/posts/perceptron-algo/perceptron.py\n\n%load_ext autoreload\n%autoreload 2\nfrom perceptron import Perceptron, PerceptronOptimizer\n\nThe autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n\n\n\n\nThe below code, from our warmup, defines a function that generates a matrix and an array of random data.\n\nimport torch\nfrom matplotlib import pyplot as plt\n\ntorch.manual_seed(1234)\n\ndef perceptron_data(n_points = 300, noise = 0.2):\n    \n    y = torch.arange(n_points) &gt;= int(n_points/2)\n    X = y[:, None] + torch.normal(0.0, noise, size = (n_points,2))\n    X = torch.cat((X, torch.ones((X.shape[0], 1))), 1)\n\n    # convert y from {0, 1} to {-1, 1}\n    y = 2*y - 1\n\n    return X, y\n\nX, y = perceptron_data(n_points = 300, noise = 0.2)\n\nprint(y)\n\ntensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n        -1, -1, -1, -1, -1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1])\n\n\nThe below code is a quick check to ensure the Perceptron code was written correctly. The output of tensor(True) shows Perceptron is probably fine.\n\np = Perceptron()\ns = p.score(X)\nl = p.loss(X, y)\nprint(l)\nprint(l == 0.5)\n\ntensor(0.5000)\ntensor(True)\n\n\nThe below code is our core training loop as a function. As long as the loss exceeds our loss threshold (which by default is 0), we perform the optimizer’s step function to update the weights and then try again. We only iterate up to our max iterations value, which is 1000 times by default.\nIf our final loss vector (loss_vec) value is 0, our program successfully found a weight vector that linearly separates our data.\n\n# instantiate a model and an optimizer\np = Perceptron() \nopt = PerceptronOptimizer(p)\nloss_vec = []\n\ndef train(X, y, max_iterations = 1000, loss_threshold = 0.0):\n    loss = 1.0\n\n    # for keeping track of loss values and number of iterations\n    j = 0\n    n = X.size()[0]\n\n    while loss &gt; loss_threshold and j &lt; max_iterations: # dangerous -- only terminates if data is linearly separable\n        j += 1\n        loss = p.loss(X, y) \n        loss_vec.append(loss)\n        \n        # pick a random data point\n        i = torch.randint(n, size = (1,))\n        x_i = X[[i],:]\n        y_i = y[i]\n        \n        # perform a perceptron update using the random data point\n        opt.step(x_i, y_i)\n    return loss_vec\n\nloss_vec = train(X,y)\nprint(\"Last Vector: \" + str(loss_vec[len(loss_vec)-1]))\nprint(p.w)\n\nLast Vector: tensor(0.)\ntensor([ 2.5406,  0.9279, -1.8141])\n\n\nThe above output shows the final vector in loss_vec is a 0, showing we managed to find a set of weights that minimize the loss. The weights are shown above below the last vector in loss_vec."
  },
  {
    "objectID": "posts/perceptron-algo/perceptron-algo.html#introduction",
    "href": "posts/perceptron-algo/perceptron-algo.html#introduction",
    "title": "Implementing the Perceptron Algorithm",
    "section": "",
    "text": "In this blog post, I implement and test the perceptron algorithm using randomly generated data. The algorithm attempts to categorize data points but is only able reach a loss of zero if the data is linearly separable. I implement the minibatch perceptron algorithm as well, which computes weight updates using multiple observations at a time. For linearly separable data, I find it’s possible to consistently achieve a loss of 0. For data that is not linearly separable, I don’t achieve a loss of 0 with the minibatch perceptron algorithm (where number of observations = number of points used to update at once) but instead see a leveling out at a loss of around 0.28.\nLink to Perceptron Python Code: https://github.com/jjr2024/github_jjr2024.github.io/blob/main/posts/perceptron-algo/perceptron.py\n\n%load_ext autoreload\n%autoreload 2\nfrom perceptron import Perceptron, PerceptronOptimizer\n\nThe autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n\n\n\n\nThe below code, from our warmup, defines a function that generates a matrix and an array of random data.\n\nimport torch\nfrom matplotlib import pyplot as plt\n\ntorch.manual_seed(1234)\n\ndef perceptron_data(n_points = 300, noise = 0.2):\n    \n    y = torch.arange(n_points) &gt;= int(n_points/2)\n    X = y[:, None] + torch.normal(0.0, noise, size = (n_points,2))\n    X = torch.cat((X, torch.ones((X.shape[0], 1))), 1)\n\n    # convert y from {0, 1} to {-1, 1}\n    y = 2*y - 1\n\n    return X, y\n\nX, y = perceptron_data(n_points = 300, noise = 0.2)\n\nprint(y)\n\ntensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n        -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n        -1, -1, -1, -1, -1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1])\n\n\nThe below code is a quick check to ensure the Perceptron code was written correctly. The output of tensor(True) shows Perceptron is probably fine.\n\np = Perceptron()\ns = p.score(X)\nl = p.loss(X, y)\nprint(l)\nprint(l == 0.5)\n\ntensor(0.5000)\ntensor(True)\n\n\nThe below code is our core training loop as a function. As long as the loss exceeds our loss threshold (which by default is 0), we perform the optimizer’s step function to update the weights and then try again. We only iterate up to our max iterations value, which is 1000 times by default.\nIf our final loss vector (loss_vec) value is 0, our program successfully found a weight vector that linearly separates our data.\n\n# instantiate a model and an optimizer\np = Perceptron() \nopt = PerceptronOptimizer(p)\nloss_vec = []\n\ndef train(X, y, max_iterations = 1000, loss_threshold = 0.0):\n    loss = 1.0\n\n    # for keeping track of loss values and number of iterations\n    j = 0\n    n = X.size()[0]\n\n    while loss &gt; loss_threshold and j &lt; max_iterations: # dangerous -- only terminates if data is linearly separable\n        j += 1\n        loss = p.loss(X, y) \n        loss_vec.append(loss)\n        \n        # pick a random data point\n        i = torch.randint(n, size = (1,))\n        x_i = X[[i],:]\n        y_i = y[i]\n        \n        # perform a perceptron update using the random data point\n        opt.step(x_i, y_i)\n    return loss_vec\n\nloss_vec = train(X,y)\nprint(\"Last Vector: \" + str(loss_vec[len(loss_vec)-1]))\nprint(p.w)\n\nLast Vector: tensor(0.)\ntensor([ 2.5406,  0.9279, -1.8141])\n\n\nThe above output shows the final vector in loss_vec is a 0, showing we managed to find a set of weights that minimize the loss. The weights are shown above below the last vector in loss_vec."
  },
  {
    "objectID": "posts/new-test-post/index.html",
    "href": "posts/new-test-post/index.html",
    "title": "Second Post",
    "section": "",
    "text": "This is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/new-test-post/index.html#math",
    "href": "posts/new-test-post/index.html#math",
    "title": "Second Post",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "posts/logistic-regression/logistic-regression.html",
    "href": "posts/logistic-regression/logistic-regression.html",
    "title": "Implementing Logistic Regression",
    "section": "",
    "text": "%load_ext autoreload\n%autoreload 2\nfrom logistic import LogisticRegression, GradientDescentOptimizer\nimport torch\nfrom matplotlib import pyplot as plt\n\nThe autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\nLink to logistic.py on GitHub: https://github.com/jjr2024/github_jjr2024.github.io/blob/main/posts/logistic-regression/logistic.py"
  },
  {
    "objectID": "posts/logistic-regression/logistic-regression.html#introduction",
    "href": "posts/logistic-regression/logistic-regression.html#introduction",
    "title": "Implementing Logistic Regression",
    "section": "Introduction",
    "text": "Introduction\nIn this blog post, I drop down a level of abstraction from prior work in the class to implement the logistic regression model. I run multiple experiments to confirm the validity of my implementation and to see how the model reacts to changes in hyperparameters (specifically beta and number of features). I find that beta &gt; 0 allows for a faster convergence to a zero or near-zero loss and that when the number of features &gt; number of observations, the model is prone to overfitting."
  },
  {
    "objectID": "posts/logistic-regression/logistic-regression.html#part-a-implement-logistic-regression",
    "href": "posts/logistic-regression/logistic-regression.html#part-a-implement-logistic-regression",
    "title": "Implementing Logistic Regression",
    "section": "Part A: Implement Logistic Regression",
    "text": "Part A: Implement Logistic Regression\nThe below function generates data for a classication problem: n_points controls the number of observations generated. Noise determines the difficulty of the problem. p_dims controls the number of features.\n\ndef classification_data(n_points = 300, noise = 0.2, p_dims = 2):\n    \n    y = torch.arange(n_points) &gt;= int(n_points/2)\n    y = 1.0*y\n    X = y[:, None] + torch.normal(0.0, noise, size = (n_points,p_dims))\n    X = torch.cat((X, torch.ones((X.shape[0], 1))), 1)\n    \n    return X, y\n\nThe below defines a function, train(), that trains the logistic regression model on X, y inputs and keeps track of the evolution of the loss over time via the loss_vec. Train() has parameters for the maximum number of update iterations (max_iterations), as well as for the learning rate (a) and the momentum rate (b).\n\nLR = LogisticRegression() \nopt = GradientDescentOptimizer(LR)\n\nloss_vec = []\n\nX, y = classification_data(n_points = 100, noise = 0.1)\n\ndef train(X, y, max_iterations = 1000, a = 0.1, b = 0.9):\n    for _ in range(max_iterations):\n        loss = LR.loss(X, y) \n        loss_vec.append(loss)\n        opt.step(X, y, a, b)\n\ntrain(X,y,1000,0.1,0.9)\n\nThe below is code defining two functions that assist in visualizing our results. plot_perceptron_data and draw_line visualize our datapoints and our weight vector, respectively.\n\ndef plot_perceptron_data(X, y, ax):\n    assert X.shape[1] == 3, \"This function only works for data created with p_dims == 2\"\n    targets = [0, 1]\n    markers = [\"o\" , \",\"]\n    for i in range(2):\n        ix = y == targets[i]\n        ax.scatter(X[ix,0], X[ix,1], s = 20,  c = y[ix], facecolors = \"none\", edgecolors = \"darkgrey\", cmap = \"BrBG\", vmin = -2, vmax = 2, alpha = 0.5, marker = markers[i])\n    ax.set(xlabel = r\"$x_1$\", ylabel = r\"$x_2$\")\n\nfig, ax = plt.subplots(1, 1)\nplot_perceptron_data(X, y, ax)\n\ndef draw_line(w, x_min, x_max, ax, **kwargs):\n    w_ = w.flatten()\n    x = torch.linspace(x_min, x_max, 101)\n    y = -(w_[0]*x + w_[2])/w_[1]\n    l = ax.plot(x, y, **kwargs)\n\ndraw_line(LR.w, 0, 1, ax, color = \"black\", linestyle = \"dashed\", label = \"weight vector w\")"
  },
  {
    "objectID": "posts/logistic-regression/logistic-regression.html#part-b-experiments",
    "href": "posts/logistic-regression/logistic-regression.html#part-b-experiments",
    "title": "Implementing Logistic Regression",
    "section": "Part B: Experiments",
    "text": "Part B: Experiments\n\nExperiment 1: Vanilla Gradient Descent\nIn this first experiment, our data has two features, alpha is small (0.2), and beta = 0. This experiment confirms that our code in Part A is likely correct.\n\nLR = LogisticRegression() \nopt = GradientDescentOptimizer(LR)\n\nloss_vec = []\n\nX, y = classification_data(n_points = 100, noise = 0.1, p_dims = 2)\n\ntrain(X,y,1000,a=0.2,b=0.0)\n\nplt.plot(loss_vec, color = \"slategrey\")\nplt.scatter(torch.arange(len(loss_vec)), loss_vec, color = \"slategrey\")\nlabs = plt.gca().set(xlabel = \"Perceptron Iteration (Updates Only)\", ylabel = \"Loss\")\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(1, 1)\nplot_perceptron_data(X, y, ax)\ndraw_line(LR.w, 0, 1, ax, color = \"black\", linestyle = \"dashed\", label = \"weight vector w\")\n\n\n\n\n\n\n\n\nThe above visualization shows that our data is linearly separable and that our weight vector correctly classifies the data with 100% accuracy.\n\n\nExperiment 2: Benefits of Momentum\nIn this experiment, we set beta = 0.9 to see the benefits of momentum, with which we need fewer iterations to approach a loss of 0.\n\nLR = LogisticRegression() \nopt = GradientDescentOptimizer(LR)\n\nloss_vec2 = loss_vec\n\nloss_vec = []\n\n#No classification_data call so that we use same dataset\n\ntrain(X,y,1000,a=0.2,b=0.9)\n\nplt.plot(loss_vec, color = \"blue\")\nplt.plot(loss_vec2, color = \"slategrey\")\nplt.scatter(torch.arange(len(loss_vec)), loss_vec, color = \"blue\")\nplt.scatter(torch.arange(len(loss_vec2)), loss_vec2, color = \"slategrey\")\nlabs = plt.gca().set(xlabel = \"Perceptron Iteration (Updates Only)\", ylabel = \"Loss\")\n\n\n\n\n\n\n\n\nThe blue line indicates our loss vector when we train our model with b = 0.9. The grey line is the loss vector from Experiment 1. We see early on that momentum can work against us initially, but ultimately does lead to a faster zero or near-zero loss.\n\nfig, ax = plt.subplots(1, 1)\nplot_perceptron_data(X, y, ax)\ndraw_line(LR.w, 0, 1, ax, color = \"black\", linestyle = \"dashed\", label = \"weight vector w\")\n\n\n\n\n\n\n\n\nAgain we achieve 100% accuracy in classification, as shown by our weight vector accurately separating the two groups of data.\n\n\nExperiment 3: Overfitting\nIn this experiment, we set the number of observations (15) to be half the number of features (30). We also create two sets of classification data, each with 15 observations, to see how our logistic regression model overfits to the training data and sees a deterioration in accuracy on our test data.\n\nLR = LogisticRegression() \nopt = GradientDescentOptimizer(LR)\n\nloss_vec = []\n\nX_train, y_train = classification_data(n_points = 15, noise = 0.5, p_dims = 30)\nX_test, y_test = classification_data(n_points = 15, noise = 0.5, p_dims = 30)\n\n\ntrain(X_train,y_train,100,a=0.1,b=0.0)\n\n(LR.predict(X_train) == y_train).float().mean(), (LR.predict(X_test) == y_test).float().mean()\n\n(tensor(1.), tensor(1.))\n\n\nAbove, the first tensor, 1., reflects our 100% accuracy on our training. The second tensor reflects 93.33% accuracy in our testing data set.\nThe difference in accuracy rates reflects our model’s overfitting on the training set."
  },
  {
    "objectID": "posts/logistic-regression/logistic-regression.html#part-c-writing-conclusion",
    "href": "posts/logistic-regression/logistic-regression.html#part-c-writing-conclusion",
    "title": "Implementing Logistic Regression",
    "section": "Part C: Writing / Conclusion",
    "text": "Part C: Writing / Conclusion\nIn this blog post, I run experiments to confirm the validity of my implementation and to see how the model reacts to changes in hyperparameters (specifically beta and number of features). I find that beta &gt; 0 allows for a faster convergence to a zero or near-zero loss and that when the number of features &gt; number of observations, the model is prone to overfitting.\nIn writing this blog post, I learned about why momentum is useful for gradient descent and why in practice beta = 0.9 is common. I gained more familiarity turning mathematical equations into code. I had a more efficient process than previous posts because of more effective debugging, especially by knowing what to look for (the shape() function to different tensors was extremely useful to know when I did something wrong)."
  },
  {
    "objectID": "posts/decision-making/DecisionMaking.html",
    "href": "posts/decision-making/DecisionMaking.html",
    "title": "Decision Making",
    "section": "",
    "text": "Introduction: In this post, I analyze data, construct a logistic regression model, and make predictions on a test dataset to understand a simplified but relatively realistic decisionmaking process to find whether to make a loan to a borrower given information on their personal finances, their requested loan, and their employment history. I find a bank can maximize its profits by lending to a small number of higher-income individuals with smaller requested loans, longer credit histories, and more years of employment. Loans for different purposes have varying default rates and are correspondingly approved at different rates–medical loans in particular are more often rejected but have the highest default rates. Using a definition of fairness related to minimizing harm, I argue that it’s reasonable for a bank to have lower approval ratings for medical loans so it can minimize harm to its own stakeholders.\nI have neither given nor received unauthorized aid on this assignment - James Ohr\n\n\n\n#Importing the data and storing it in variable df_train\n\nimport pandas as pd\nurl = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/credit-risk/train.csv\"\ndf_train = pd.read_csv(url)\n\n\n\n\n\ndf_train.head()\n\n\n\n\n\n\n\n\n\nperson_age\nperson_income\nperson_home_ownership\nperson_emp_length\nloan_intent\nloan_grade\nloan_amnt\nloan_int_rate\nloan_status\nloan_percent_income\ncb_person_default_on_file\ncb_person_cred_hist_length\n\n\n\n\n0\n25\n43200\nRENT\nNaN\nVENTURE\nB\n1200\n9.91\n0\n0.03\nN\n4\n\n\n1\n27\n98000\nRENT\n3.0\nEDUCATION\nC\n11750\n13.47\n0\n0.12\nY\n6\n\n\n2\n22\n36996\nRENT\n5.0\nEDUCATION\nA\n10000\n7.51\n0\n0.27\nN\n4\n\n\n3\n24\n26000\nRENT\n2.0\nMEDICAL\nC\n1325\n12.87\n1\n0.05\nN\n4\n\n\n4\n29\n53004\nMORTGAGE\n2.0\nHOMEIMPROVEMENT\nA\n15000\n9.63\n0\n0.28\nN\n10\n\n\n\n\n\n\n\n\nThe above table helps me get a sense of the variables in the dataset and their types.\n\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\ng = sns.displot(df_train, x=\"loan_percent_income\", hue=\"loan_status\", element=\"step\", legend=False)\nplt.legend(title='Loan Status', loc='upper right', labels=['Default', 'No Default'])\ng.set(xlabel=\"Loan Proportion of Income\")\nplt.show(g)\n\n\n\n\n\n\n\n\nThe above figure shows that there are * significantly more borrowers who didn’t default than those who did * individuals who receive a loan less than 30% of their income are unlikely to default on their loan * individuals who receive a loan over 30% of their income are significantly more likely to default than not.\n\ng = sns.displot(df_train, x=\"loan_int_rate\", hue=\"loan_intent\", kind=\"kde\")\ng.legend.set_title(\"Loan Purpose\")\ng.set(xlabel=\"Loan Interest Rate (%)\")\nplt.show(g)\n\n\n\n\n\n\n\n\nThe above figure shows an interesting pattern across every single type of loan. Each distribution is approximately bimodal (although some have three local maxima). It’s unsurprising, but there are far more people under the second peak, i.e., the higher interest rate peak, for each type of loan.\n\ndf_train.groupby(\"loan_intent\").mean(numeric_only=True)\n\n\n\n\n\n\n\n\n\nperson_age\nperson_income\nperson_emp_length\nloan_amnt\nloan_int_rate\nloan_status\nloan_percent_income\ncb_person_cred_hist_length\n\n\nloan_intent\n\n\n\n\n\n\n\n\n\n\n\n\nDEBTCONSOLIDATION\n27.588798\n66693.453327\n4.759419\n9620.901149\n10.983305\n0.287458\n0.170869\n5.695548\n\n\nEDUCATION\n26.597620\n63847.711917\n4.440192\n9460.015604\n10.965465\n0.173396\n0.169352\n5.141603\n\n\nHOMEIMPROVEMENT\n28.981737\n73082.079600\n5.103754\n10348.725017\n11.160075\n0.264645\n0.166733\n6.430048\n\n\nMEDICAL\n27.950982\n61314.583868\n4.782062\n9242.269907\n11.051946\n0.263289\n0.172825\n5.913547\n\n\nPERSONAL\n28.288339\n68070.502495\n4.897997\n9549.427178\n11.009814\n0.193739\n0.168671\n6.151316\n\n\nVENTURE\n27.588643\n66098.818162\n4.877869\n9516.417425\n10.940866\n0.148678\n0.170130\n5.744040\n\n\n\n\n\n\n\n\nBorrowers intending to use loans for home improvement tend to: * have higher incomes * receive greater loans * tend to have higher default rates, which are in line with default rates of loans for medical and debt consolidation.\nMedical loan borrowers tend to have the lowest incomes, the highest loan-to-income ratios, and the lowest loan amounts. The first observation is most surprising–I would have expected education loan borrowers to have the lowest incomes (maybe this has to do with co-signers).\n\n\n\nThe below code pre-processes our data for use in the model. We drop the “loan_grade” variable, which the instructions disallow for building th emodel. We separate out “loan status” into an outcome variable, y. We transform categorical variables from strings into numbers.\n\n#Data pre-processing\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\n\ndef prepare_data(df):\n  df = df_train.drop([\"loan_grade\"], axis = 1)\n  df = df.dropna()\n  le.fit(df_train[\"person_home_ownership\"])\n  df[\"person_home_ownership\"] = le.transform(df[\"person_home_ownership\"])\n  le.fit(df_train[\"loan_intent\"])\n  df[\"loan_intent\"] = le.transform(df[\"loan_intent\"])\n  y = df[\"loan_status\"]\n  df = df.drop([\"loan_status\"], axis = 1)\n  df = pd.get_dummies(df)\n  return df, y\n\nX_train, y_train = prepare_data(df_train)\ndf_train = df_train.dropna()\n\nBelow, I chose the features for the model and fitted our model to our training data. I chose income and loan amount because they’re the two components of the loan-to-income ratio, which seemed to be relatively revealing in the above chart showing loan status vs. loan-to-income. Adding employment length didn’t actually change the accuracy of the model, but I added it just because intuitively I thought it might have an impact even though the table above didn’t show anything particularly interesting regarding the variable.\n\n#Choosing features\nfrom sklearn.linear_model import LogisticRegression\n\nLR = LogisticRegression()\n\ncols = [\"person_income\", \"loan_amnt\", \"person_emp_length\"]\n\nLR.fit(X_train[cols], y_train)\nLR.score(X_train[cols], y_train)\nLR.coef_[0]\n\narray([-4.05735465e-05,  1.06559046e-04, -2.48736069e-08])\n\n\n\n\n\nBelow we have code that (1) finds the profit the bank makes from all of its loans (we ignore any NAs) and (2) identifies the threshold that maximizes profit.\n\n#This function, taken from the week 2 lecture notes and just slightly modified to allow for a third x variable, calculates the risk score for a borrower. \ndef linear_score(w, x0, x1, x2):\n    return w[0]*x0 + w[1]*x1 + w[2]*x2\n\n\n#Predict makes binary predictions for data using a supplied score function with weights w and a supplied threshold. Taken from lecture notes from week 2.\n#We begin with a 0 threshold but later on test others to find an optimal threshold\n\nt = 0\n\ndef predict(score_fun, w, threshold, df):\n    \"\"\"\n    make binary predictions for data df using a supplied score function with weights w and supplied threshold. \n    \"\"\"\n    scores = score_fun(w, df[\"person_income\"], df[\"loan_amnt\"], df[\"person_emp_length\"])\n    return 1*(scores &gt; threshold)\n\ndf_train[\"decision\"] = predict(linear_score, LR.coef_[0], t, df_train)\n(df_train[\"decision\"] == df_train[\"loan_status\"]).mean()\n\n0.8080062862880342\n\n\n\n# Creating a funciton to find profit\n#The loan_int_rate variable is expressed as a percentage, so we divide it by 100 to make it a regular proportion instead in both helper variables\n\n#Helper function to calculate profit for when loans are repaid, using the provided formula\ndef calculateGain(loan_amnt, loan_int_rate):\n    return np.sum(loan_amnt*(1 + 0.25*loan_int_rate/100)**10 - loan_amnt) \n\n#Helper function to calculate loss for when loans are defaulted on, using the provided formula\ndef calculateLoss(loan_amnt, loan_int_rate):\n    return np.sum(loan_amnt*(1 + 0.25*loan_int_rate/100)**3 - 1.7*loan_amnt)\n    \ndef find_profit(df):\n    #Below df_repaid and df_default are created to select only the data points the model chooses\n    df_repaid = df[df[\"loan_status\"] == 0]\n    df_repaid = df_repaid[df_repaid[\"decision\"] == 0]\n    df_default = df[df[\"loan_status\"] == 1]\n    df_default = df_default[df_default[\"decision\"] == 0]\n    \n    return calculateGain(df_repaid[\"loan_amnt\"], df_repaid[\"loan_int_rate\"]) + calculateLoss(df_default[\"loan_amnt\"], df_default[\"loan_int_rate\"])\n\nfind_profit(df_train)\n\n25068803.47746343\n\n\nThe below code runs find_profit on every integer from -100 to 100 to try to find the threshold that gets us the highest profit. We find that a threshold of -1 corresponds to the highest profit value, which is about $25 million. To find this threshold, we use the idxmax() function, which gets us the first occurance of a maximum over an axis. In this case, it helps us find whatever threshold corresponds to the highest profit.\n\niterations = 200\npredictions = []\nfor i in range(iterations):\n    threshold = (-iterations/2)+(i)\n    df_train[\"decision\"] = predict(linear_score, LR.coef_[0], threshold, df_train)\n    predictions.append((threshold, find_profit(df_train)))\n\n\npredictions_df = pd.DataFrame(data=predictions)\npredictions_df.columns =['Threshold', 'Profit']\n\nsns.relplot(data=predictions_df, x=\"Threshold\", y=\"Profit\")\npredictions_df['Threshold'][predictions_df['Profit'].idxmax()], predictions_df['Profit'].max()\n\n\n\n\n\n\n\n\nWe obtain from our output above the chart (-1.0, 25755817.698476546) that the profit-maximizing threshold is -1.\n\n\n\n\n#In these code block, we find for the training set the total profit of our model, the profit per approved borrower, and the accuracy rate.\nfinal_threshold = -1\n\ndf_train[\"decision\"] = predict(linear_score, LR.coef_[0], final_threshold, df_train)\nborrowers_count = df_train[df_train[\"decision\"]==0].count()[\"loan_int_rate\"]\nfind_profit(df_train), find_profit(df_train)/borrowers_count, (df_train[\"decision\"] == df_train[\"loan_status\"]).mean()\n\n(25755817.698476546, 1819.0421426990993, 0.6927576723272362)\n\n\n\n#In these code block, we find for the test set the total profit of our model, the profit per approved borrower, and the accuracy rate.\nurl = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/credit-risk/test.csv\"\ndf_test = pd.read_csv(url)\n\ndf_test[\"decision\"] = predict(linear_score, LR.coef_[0], final_threshold, df_test)\nborrowers_count = df_test[df_test[\"decision\"]==0].count()[\"loan_int_rate\"]\nfind_profit(df_test), find_profit(df_test)/borrowers_count, (df_test[\"decision\"] == df_test[\"loan_status\"]).mean()\n\n(5965836.794978274, 1632.2398891869423, 0.6898879852692957)\n\n\nWhat is the expected profit per borrower on the test set? Is it similar to your profit on the training set?\nThe profit per borrower was lower in the test dataset ($1,632) than the training dataset ($1,819), but the accuracy was similar, where accuracy is defined as the % of the time our default prediction actually matched the borrower’s default status.\nTraining accuracy: 69.3%\nTesting accuracy: 69.0%\n\n\n\n\ndf_test.groupby([\"loan_intent\"])[[\"loan_status\", \"decision\"]].mean(numeric_only=True)\n\n\n\n\n\n\n\n\n\nloan_status\ndecision\n\n\nloan_intent\n\n\n\n\n\n\nDEBTCONSOLIDATION\n0.279497\n0.386847\n\n\nEDUCATION\n0.167421\n0.401961\n\n\nHOMEIMPROVEMENT\n0.246088\n0.270270\n\n\nMEDICAL\n0.281553\n0.406958\n\n\nPERSONAL\n0.219227\n0.385445\n\n\nVENTURE\n0.145701\n0.361086\n\n\n\n\n\n\n\n\nThe above table shows us the default rates by loan category, as well as what proportion of borrowers were approved by our model. Medical loans have the highest rejection rates and the highest default rates.\n\ndf_test.groupby([\"decision\"]).mean(numeric_only=True)\n\n\n\n\n\n\n\n\n\nperson_age\nperson_income\nperson_emp_length\nloan_amnt\nloan_int_rate\nloan_status\nloan_percent_income\ncb_person_cred_hist_length\n\n\ndecision\n\n\n\n\n\n\n\n\n\n\n\n\n0\n28.064977\n82754.051932\n5.244782\n8949.870785\n10.709193\n0.123554\n0.115412\n6.052670\n\n\n1\n27.189894\n39522.220049\n4.133252\n10859.555827\n11.528797\n0.381011\n0.263394\n5.496333\n\n\n\n\n\n\n\n\nThe above table shows us the different average statistics of approved vs. rejected borrowers. Approved borrowers tend to be slightly older, have much higher income, have longer employment histories, ask for smaller loans, ask for loans that represent a smaller proportion of their income, and have longer credit histories.\n\nbins = np.array([1,20,40,60,80,100])\ndf_test[\"person_age\"] = pd.cut(df_test[\"person_age\"].astype('Int64'), bins, include_lowest=True)\n\n\ng = sns.barplot(data=df_test, x=\"person_age\", y=\"decision\", color='blue')\ng.set(xlabel=\"Person Age Range\", ylabel=\"% of Age Range Rejected (w/ Confidence Intervals)\")\nplt.show(g)\n\n\n\n\n\n\n\n\nThe above table shows the average decision rating for each age range (bucketed by 20 years). The Y axis shows what % of the age range is rejected. The lines on the bars indicate 95% confidence intervals.\nQuestions: 1. Is it more difficult for people in certain age groups to access credit under your proposed system? 2. Is it more difficult for people to get loans in order to pay for medical expenses? 2a. How does this compare with the actual rate of default in that group? 2b. What about people seeking loans for business ventures or education? 3. How does a person’s income level impact the ease with which they can access credit under your decision system?\nResponse:\nFor the purpose of this discussion, we will consider a loan “rejected” if the model deems the loan too-high risk. All statistics are based on the test dataset.\n\nWhile the 20-40 and 40-60 age ranges seem to have about the same access to credit, the 60-80 age group has a significantly higher chance of being rejected–i.e., have lower access to credit. Younger borrowers seem to have the greatest variability in access to credit but generally have high access\nCompared to loans for other purposes, loans for medical expenses are frequently considered too high-risk to make according to our model. Our model is, in a sense, generous: 28.2% of medical borrowers defaulted, but 40.7% were considered too high-risk. In contrast, business venture loans were denied 36.1% of the time with 14.6% risk of default, so the default rate and rejection rate were even further apart. For loans for education, 40.2% of borrowers were rejected, while 16.7% of borrowers actually defaulted. So even though a 40.7% rejection rate for medical borrowers is higher than loans for other purposes, the rejection rate seems reasonable when we consider the high default rate of medical loans.\nThe higher the income, the lower the perceived risk by the model. This is clearest in the simple table above that groups individuals by the “decision” column results. The borrowers the model would accept have about 13 more months of work experience, request loans that are smaller by about $2,000, and have credit histories that are 6 months longer. But the starkest differences are in the income of the borrower and (2) the percentage of income the loan represented, which is directly related to income. The income of approved borrowers is about double the income of rejected borrowers. The loan-to-income ratio is about three times higher for rejected borrowers than approved borrowers.\n\n\n\n\nDiscussion on Fairness\nConsidering that people seeking loans for medical expense have high rates of default, is it fair that it is more difficult for them to obtain access to credit?\nFairness\nFairness in decision-making is to make choices that minimize harm to all parties, with particular regard to parties with low/no control.\nControl\nThe bank has full control over whether to make the loan, so they clearly have substantial control. The borrower has far less control but not no control–excluding cases in which people have a serious illness / injury that prevents them from working, they have some level of control over their personal finances, particularly their income. Still, the borrower has likely little control over the size of the loan they need given the nature of medical expenses and, relatedly, the percentage of income their loan constitutes. So in this way, it’s unlikely that a perfectly fair decision can be made. But the bank has to make a decision, and so the goal should be to achieve a target that gets as close to fairness as possible.\nHarm\nIt is not only the borrower who can experience harm in this scenario by being denied a loan. The bank experiences financial harm by lending to a borrower with excessively high risk. This harm is harder to see immediately–it’s distributed in the form of risk or loss across shareholders, management, employees, depositors, lenders, etc, but it’s harm nonetheless. And if a bank were to repeatedly make loans with negative expected value, it risks serious harm to those stakeholders (e.g., people losing savings in the bank’s stock; employees losing jobs; depositors losing uninsured deposits).\nIt’s possible the bank could just make loans with lower expected value instead, not negative expected value. But even that could mean a decline in the business over time as competitors generate greater profits and reinvest those profits to become more competitive, harming this bank’s business and hence its stakeholders.\nIn conclusion, balancing the benefit to the bank’s stakeholders with the potential harm to rejected borrowers, I conclude that it is fair for medical loan borrowers to have more difficulty accessing credit.\nTo reach a conclusion about whether this specific model and its decisions are fair, we would have to make assumptions about the level of harm being done to rejected borrowers and the benefit to stakeholders in the bank from those borrowers being rejected.\nReflection on Blog Post\nI found that it is possible to construct a logistic regression model that can predict borrower outcomes with relative accuracy. One of the most interesting findings was that in this case, to maximize our target variable, we actually didn’t optimize accuracy. A threshold of 0 yields around 80% accuracy on the training set, far higher than our profit-maximizing threshold of -1, which yields 69% accuracy on the training set. I learned more about how to visualize data and had to grapple with the best ways to visualize so many variables. I ultimately concluded that I would keep my graphs relatively simple and show a more complete story via tables. I learned to work with subsets of my own data: Part D in particular was tricky for me because I had trouble finding a way to construct the find_profit function.\nUnlike the Classifying Penguins post, there was a lot less guidance, which I think was helpful in forcing me to edit and therefore engage further with the example code given previously (e.g., pre-processing the data at the start of Part C)"
  },
  {
    "objectID": "posts/decision-making/DecisionMaking.html#part-a-grab-the-data",
    "href": "posts/decision-making/DecisionMaking.html#part-a-grab-the-data",
    "title": "Decision Making",
    "section": "",
    "text": "#Importing the data and storing it in variable df_train\n\nimport pandas as pd\nurl = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/credit-risk/train.csv\"\ndf_train = pd.read_csv(url)"
  },
  {
    "objectID": "posts/decision-making/DecisionMaking.html#part-b-explore-the-data",
    "href": "posts/decision-making/DecisionMaking.html#part-b-explore-the-data",
    "title": "Decision Making",
    "section": "",
    "text": "df_train.head()\n\n\n\n\n\n\n\n\n\nperson_age\nperson_income\nperson_home_ownership\nperson_emp_length\nloan_intent\nloan_grade\nloan_amnt\nloan_int_rate\nloan_status\nloan_percent_income\ncb_person_default_on_file\ncb_person_cred_hist_length\n\n\n\n\n0\n25\n43200\nRENT\nNaN\nVENTURE\nB\n1200\n9.91\n0\n0.03\nN\n4\n\n\n1\n27\n98000\nRENT\n3.0\nEDUCATION\nC\n11750\n13.47\n0\n0.12\nY\n6\n\n\n2\n22\n36996\nRENT\n5.0\nEDUCATION\nA\n10000\n7.51\n0\n0.27\nN\n4\n\n\n3\n24\n26000\nRENT\n2.0\nMEDICAL\nC\n1325\n12.87\n1\n0.05\nN\n4\n\n\n4\n29\n53004\nMORTGAGE\n2.0\nHOMEIMPROVEMENT\nA\n15000\n9.63\n0\n0.28\nN\n10\n\n\n\n\n\n\n\n\nThe above table helps me get a sense of the variables in the dataset and their types.\n\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\ng = sns.displot(df_train, x=\"loan_percent_income\", hue=\"loan_status\", element=\"step\", legend=False)\nplt.legend(title='Loan Status', loc='upper right', labels=['Default', 'No Default'])\ng.set(xlabel=\"Loan Proportion of Income\")\nplt.show(g)\n\n\n\n\n\n\n\n\nThe above figure shows that there are * significantly more borrowers who didn’t default than those who did * individuals who receive a loan less than 30% of their income are unlikely to default on their loan * individuals who receive a loan over 30% of their income are significantly more likely to default than not.\n\ng = sns.displot(df_train, x=\"loan_int_rate\", hue=\"loan_intent\", kind=\"kde\")\ng.legend.set_title(\"Loan Purpose\")\ng.set(xlabel=\"Loan Interest Rate (%)\")\nplt.show(g)\n\n\n\n\n\n\n\n\nThe above figure shows an interesting pattern across every single type of loan. Each distribution is approximately bimodal (although some have three local maxima). It’s unsurprising, but there are far more people under the second peak, i.e., the higher interest rate peak, for each type of loan.\n\ndf_train.groupby(\"loan_intent\").mean(numeric_only=True)\n\n\n\n\n\n\n\n\n\nperson_age\nperson_income\nperson_emp_length\nloan_amnt\nloan_int_rate\nloan_status\nloan_percent_income\ncb_person_cred_hist_length\n\n\nloan_intent\n\n\n\n\n\n\n\n\n\n\n\n\nDEBTCONSOLIDATION\n27.588798\n66693.453327\n4.759419\n9620.901149\n10.983305\n0.287458\n0.170869\n5.695548\n\n\nEDUCATION\n26.597620\n63847.711917\n4.440192\n9460.015604\n10.965465\n0.173396\n0.169352\n5.141603\n\n\nHOMEIMPROVEMENT\n28.981737\n73082.079600\n5.103754\n10348.725017\n11.160075\n0.264645\n0.166733\n6.430048\n\n\nMEDICAL\n27.950982\n61314.583868\n4.782062\n9242.269907\n11.051946\n0.263289\n0.172825\n5.913547\n\n\nPERSONAL\n28.288339\n68070.502495\n4.897997\n9549.427178\n11.009814\n0.193739\n0.168671\n6.151316\n\n\nVENTURE\n27.588643\n66098.818162\n4.877869\n9516.417425\n10.940866\n0.148678\n0.170130\n5.744040\n\n\n\n\n\n\n\n\nBorrowers intending to use loans for home improvement tend to: * have higher incomes * receive greater loans * tend to have higher default rates, which are in line with default rates of loans for medical and debt consolidation.\nMedical loan borrowers tend to have the lowest incomes, the highest loan-to-income ratios, and the lowest loan amounts. The first observation is most surprising–I would have expected education loan borrowers to have the lowest incomes (maybe this has to do with co-signers)."
  },
  {
    "objectID": "posts/decision-making/DecisionMaking.html#part-c-build-a-model",
    "href": "posts/decision-making/DecisionMaking.html#part-c-build-a-model",
    "title": "Decision Making",
    "section": "",
    "text": "The below code pre-processes our data for use in the model. We drop the “loan_grade” variable, which the instructions disallow for building th emodel. We separate out “loan status” into an outcome variable, y. We transform categorical variables from strings into numbers.\n\n#Data pre-processing\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\n\ndef prepare_data(df):\n  df = df_train.drop([\"loan_grade\"], axis = 1)\n  df = df.dropna()\n  le.fit(df_train[\"person_home_ownership\"])\n  df[\"person_home_ownership\"] = le.transform(df[\"person_home_ownership\"])\n  le.fit(df_train[\"loan_intent\"])\n  df[\"loan_intent\"] = le.transform(df[\"loan_intent\"])\n  y = df[\"loan_status\"]\n  df = df.drop([\"loan_status\"], axis = 1)\n  df = pd.get_dummies(df)\n  return df, y\n\nX_train, y_train = prepare_data(df_train)\ndf_train = df_train.dropna()\n\nBelow, I chose the features for the model and fitted our model to our training data. I chose income and loan amount because they’re the two components of the loan-to-income ratio, which seemed to be relatively revealing in the above chart showing loan status vs. loan-to-income. Adding employment length didn’t actually change the accuracy of the model, but I added it just because intuitively I thought it might have an impact even though the table above didn’t show anything particularly interesting regarding the variable.\n\n#Choosing features\nfrom sklearn.linear_model import LogisticRegression\n\nLR = LogisticRegression()\n\ncols = [\"person_income\", \"loan_amnt\", \"person_emp_length\"]\n\nLR.fit(X_train[cols], y_train)\nLR.score(X_train[cols], y_train)\nLR.coef_[0]\n\narray([-4.05735465e-05,  1.06559046e-04, -2.48736069e-08])"
  },
  {
    "objectID": "posts/decision-making/DecisionMaking.html#part-d-find-a-threshold",
    "href": "posts/decision-making/DecisionMaking.html#part-d-find-a-threshold",
    "title": "Decision Making",
    "section": "",
    "text": "Below we have code that (1) finds the profit the bank makes from all of its loans (we ignore any NAs) and (2) identifies the threshold that maximizes profit.\n\n#This function, taken from the week 2 lecture notes and just slightly modified to allow for a third x variable, calculates the risk score for a borrower. \ndef linear_score(w, x0, x1, x2):\n    return w[0]*x0 + w[1]*x1 + w[2]*x2\n\n\n#Predict makes binary predictions for data using a supplied score function with weights w and a supplied threshold. Taken from lecture notes from week 2.\n#We begin with a 0 threshold but later on test others to find an optimal threshold\n\nt = 0\n\ndef predict(score_fun, w, threshold, df):\n    \"\"\"\n    make binary predictions for data df using a supplied score function with weights w and supplied threshold. \n    \"\"\"\n    scores = score_fun(w, df[\"person_income\"], df[\"loan_amnt\"], df[\"person_emp_length\"])\n    return 1*(scores &gt; threshold)\n\ndf_train[\"decision\"] = predict(linear_score, LR.coef_[0], t, df_train)\n(df_train[\"decision\"] == df_train[\"loan_status\"]).mean()\n\n0.8080062862880342\n\n\n\n# Creating a funciton to find profit\n#The loan_int_rate variable is expressed as a percentage, so we divide it by 100 to make it a regular proportion instead in both helper variables\n\n#Helper function to calculate profit for when loans are repaid, using the provided formula\ndef calculateGain(loan_amnt, loan_int_rate):\n    return np.sum(loan_amnt*(1 + 0.25*loan_int_rate/100)**10 - loan_amnt) \n\n#Helper function to calculate loss for when loans are defaulted on, using the provided formula\ndef calculateLoss(loan_amnt, loan_int_rate):\n    return np.sum(loan_amnt*(1 + 0.25*loan_int_rate/100)**3 - 1.7*loan_amnt)\n    \ndef find_profit(df):\n    #Below df_repaid and df_default are created to select only the data points the model chooses\n    df_repaid = df[df[\"loan_status\"] == 0]\n    df_repaid = df_repaid[df_repaid[\"decision\"] == 0]\n    df_default = df[df[\"loan_status\"] == 1]\n    df_default = df_default[df_default[\"decision\"] == 0]\n    \n    return calculateGain(df_repaid[\"loan_amnt\"], df_repaid[\"loan_int_rate\"]) + calculateLoss(df_default[\"loan_amnt\"], df_default[\"loan_int_rate\"])\n\nfind_profit(df_train)\n\n25068803.47746343\n\n\nThe below code runs find_profit on every integer from -100 to 100 to try to find the threshold that gets us the highest profit. We find that a threshold of -1 corresponds to the highest profit value, which is about $25 million. To find this threshold, we use the idxmax() function, which gets us the first occurance of a maximum over an axis. In this case, it helps us find whatever threshold corresponds to the highest profit.\n\niterations = 200\npredictions = []\nfor i in range(iterations):\n    threshold = (-iterations/2)+(i)\n    df_train[\"decision\"] = predict(linear_score, LR.coef_[0], threshold, df_train)\n    predictions.append((threshold, find_profit(df_train)))\n\n\npredictions_df = pd.DataFrame(data=predictions)\npredictions_df.columns =['Threshold', 'Profit']\n\nsns.relplot(data=predictions_df, x=\"Threshold\", y=\"Profit\")\npredictions_df['Threshold'][predictions_df['Profit'].idxmax()], predictions_df['Profit'].max()\n\n\n\n\n\n\n\n\nWe obtain from our output above the chart (-1.0, 25755817.698476546) that the profit-maximizing threshold is -1."
  },
  {
    "objectID": "posts/decision-making/DecisionMaking.html#part-e-evaluate-your-model-from-the-banks-perspective",
    "href": "posts/decision-making/DecisionMaking.html#part-e-evaluate-your-model-from-the-banks-perspective",
    "title": "Decision Making",
    "section": "",
    "text": "#In these code block, we find for the training set the total profit of our model, the profit per approved borrower, and the accuracy rate.\nfinal_threshold = -1\n\ndf_train[\"decision\"] = predict(linear_score, LR.coef_[0], final_threshold, df_train)\nborrowers_count = df_train[df_train[\"decision\"]==0].count()[\"loan_int_rate\"]\nfind_profit(df_train), find_profit(df_train)/borrowers_count, (df_train[\"decision\"] == df_train[\"loan_status\"]).mean()\n\n(25755817.698476546, 1819.0421426990993, 0.6927576723272362)\n\n\n\n#In these code block, we find for the test set the total profit of our model, the profit per approved borrower, and the accuracy rate.\nurl = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/credit-risk/test.csv\"\ndf_test = pd.read_csv(url)\n\ndf_test[\"decision\"] = predict(linear_score, LR.coef_[0], final_threshold, df_test)\nborrowers_count = df_test[df_test[\"decision\"]==0].count()[\"loan_int_rate\"]\nfind_profit(df_test), find_profit(df_test)/borrowers_count, (df_test[\"decision\"] == df_test[\"loan_status\"]).mean()\n\n(5965836.794978274, 1632.2398891869423, 0.6898879852692957)\n\n\nWhat is the expected profit per borrower on the test set? Is it similar to your profit on the training set?\nThe profit per borrower was lower in the test dataset ($1,632) than the training dataset ($1,819), but the accuracy was similar, where accuracy is defined as the % of the time our default prediction actually matched the borrower’s default status.\nTraining accuracy: 69.3%\nTesting accuracy: 69.0%"
  },
  {
    "objectID": "posts/decision-making/DecisionMaking.html#part-f-evaluate-your-model-from-the-borrowers-perspective",
    "href": "posts/decision-making/DecisionMaking.html#part-f-evaluate-your-model-from-the-borrowers-perspective",
    "title": "Decision Making",
    "section": "",
    "text": "df_test.groupby([\"loan_intent\"])[[\"loan_status\", \"decision\"]].mean(numeric_only=True)\n\n\n\n\n\n\n\n\n\nloan_status\ndecision\n\n\nloan_intent\n\n\n\n\n\n\nDEBTCONSOLIDATION\n0.279497\n0.386847\n\n\nEDUCATION\n0.167421\n0.401961\n\n\nHOMEIMPROVEMENT\n0.246088\n0.270270\n\n\nMEDICAL\n0.281553\n0.406958\n\n\nPERSONAL\n0.219227\n0.385445\n\n\nVENTURE\n0.145701\n0.361086\n\n\n\n\n\n\n\n\nThe above table shows us the default rates by loan category, as well as what proportion of borrowers were approved by our model. Medical loans have the highest rejection rates and the highest default rates.\n\ndf_test.groupby([\"decision\"]).mean(numeric_only=True)\n\n\n\n\n\n\n\n\n\nperson_age\nperson_income\nperson_emp_length\nloan_amnt\nloan_int_rate\nloan_status\nloan_percent_income\ncb_person_cred_hist_length\n\n\ndecision\n\n\n\n\n\n\n\n\n\n\n\n\n0\n28.064977\n82754.051932\n5.244782\n8949.870785\n10.709193\n0.123554\n0.115412\n6.052670\n\n\n1\n27.189894\n39522.220049\n4.133252\n10859.555827\n11.528797\n0.381011\n0.263394\n5.496333\n\n\n\n\n\n\n\n\nThe above table shows us the different average statistics of approved vs. rejected borrowers. Approved borrowers tend to be slightly older, have much higher income, have longer employment histories, ask for smaller loans, ask for loans that represent a smaller proportion of their income, and have longer credit histories.\n\nbins = np.array([1,20,40,60,80,100])\ndf_test[\"person_age\"] = pd.cut(df_test[\"person_age\"].astype('Int64'), bins, include_lowest=True)\n\n\ng = sns.barplot(data=df_test, x=\"person_age\", y=\"decision\", color='blue')\ng.set(xlabel=\"Person Age Range\", ylabel=\"% of Age Range Rejected (w/ Confidence Intervals)\")\nplt.show(g)\n\n\n\n\n\n\n\n\nThe above table shows the average decision rating for each age range (bucketed by 20 years). The Y axis shows what % of the age range is rejected. The lines on the bars indicate 95% confidence intervals.\nQuestions: 1. Is it more difficult for people in certain age groups to access credit under your proposed system? 2. Is it more difficult for people to get loans in order to pay for medical expenses? 2a. How does this compare with the actual rate of default in that group? 2b. What about people seeking loans for business ventures or education? 3. How does a person’s income level impact the ease with which they can access credit under your decision system?\nResponse:\nFor the purpose of this discussion, we will consider a loan “rejected” if the model deems the loan too-high risk. All statistics are based on the test dataset.\n\nWhile the 20-40 and 40-60 age ranges seem to have about the same access to credit, the 60-80 age group has a significantly higher chance of being rejected–i.e., have lower access to credit. Younger borrowers seem to have the greatest variability in access to credit but generally have high access\nCompared to loans for other purposes, loans for medical expenses are frequently considered too high-risk to make according to our model. Our model is, in a sense, generous: 28.2% of medical borrowers defaulted, but 40.7% were considered too high-risk. In contrast, business venture loans were denied 36.1% of the time with 14.6% risk of default, so the default rate and rejection rate were even further apart. For loans for education, 40.2% of borrowers were rejected, while 16.7% of borrowers actually defaulted. So even though a 40.7% rejection rate for medical borrowers is higher than loans for other purposes, the rejection rate seems reasonable when we consider the high default rate of medical loans.\nThe higher the income, the lower the perceived risk by the model. This is clearest in the simple table above that groups individuals by the “decision” column results. The borrowers the model would accept have about 13 more months of work experience, request loans that are smaller by about $2,000, and have credit histories that are 6 months longer. But the starkest differences are in the income of the borrower and (2) the percentage of income the loan represented, which is directly related to income. The income of approved borrowers is about double the income of rejected borrowers. The loan-to-income ratio is about three times higher for rejected borrowers than approved borrowers."
  },
  {
    "objectID": "posts/decision-making/DecisionMaking.html#part-g-write-and-reflect",
    "href": "posts/decision-making/DecisionMaking.html#part-g-write-and-reflect",
    "title": "Decision Making",
    "section": "",
    "text": "Discussion on Fairness\nConsidering that people seeking loans for medical expense have high rates of default, is it fair that it is more difficult for them to obtain access to credit?\nFairness\nFairness in decision-making is to make choices that minimize harm to all parties, with particular regard to parties with low/no control.\nControl\nThe bank has full control over whether to make the loan, so they clearly have substantial control. The borrower has far less control but not no control–excluding cases in which people have a serious illness / injury that prevents them from working, they have some level of control over their personal finances, particularly their income. Still, the borrower has likely little control over the size of the loan they need given the nature of medical expenses and, relatedly, the percentage of income their loan constitutes. So in this way, it’s unlikely that a perfectly fair decision can be made. But the bank has to make a decision, and so the goal should be to achieve a target that gets as close to fairness as possible.\nHarm\nIt is not only the borrower who can experience harm in this scenario by being denied a loan. The bank experiences financial harm by lending to a borrower with excessively high risk. This harm is harder to see immediately–it’s distributed in the form of risk or loss across shareholders, management, employees, depositors, lenders, etc, but it’s harm nonetheless. And if a bank were to repeatedly make loans with negative expected value, it risks serious harm to those stakeholders (e.g., people losing savings in the bank’s stock; employees losing jobs; depositors losing uninsured deposits).\nIt’s possible the bank could just make loans with lower expected value instead, not negative expected value. But even that could mean a decline in the business over time as competitors generate greater profits and reinvest those profits to become more competitive, harming this bank’s business and hence its stakeholders.\nIn conclusion, balancing the benefit to the bank’s stakeholders with the potential harm to rejected borrowers, I conclude that it is fair for medical loan borrowers to have more difficulty accessing credit.\nTo reach a conclusion about whether this specific model and its decisions are fair, we would have to make assumptions about the level of harm being done to rejected borrowers and the benefit to stakeholders in the bank from those borrowers being rejected.\nReflection on Blog Post\nI found that it is possible to construct a logistic regression model that can predict borrower outcomes with relative accuracy. One of the most interesting findings was that in this case, to maximize our target variable, we actually didn’t optimize accuracy. A threshold of 0 yields around 80% accuracy on the training set, far higher than our profit-maximizing threshold of -1, which yields 69% accuracy on the training set. I learned more about how to visualize data and had to grapple with the best ways to visualize so many variables. I ultimately concluded that I would keep my graphs relatively simple and show a more complete story via tables. I learned to work with subsets of my own data: Part D in particular was tricky for me because I had trouble finding a way to construct the find_profit function.\nUnlike the Classifying Penguins post, there was a lot less guidance, which I think was helpful in forcing me to edit and therefore engage further with the example code given previously (e.g., pre-processing the data at the start of Part C)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Awesome CSCI 0451 Blog",
    "section": "",
    "text": "Newton’s Method for Logistic Regression\n\n\n\n\n\nA blog post about implementing and testing Newton’s method for logistic regression.\n\n\n\n\n\nMay 5, 2024\n\n\nJames Ohr\n\n\n\n\n\n\n\n\n\n\n\n\nImplementing Logistic Regression\n\n\n\n\n\nA blog post about implementing and testing the logistic regression algorithm.\n\n\n\n\n\nMay 2, 2024\n\n\nJames Ohr\n\n\n\n\n\n\n\n\n\n\n\n\nImplementing the Perceptron Algorithm\n\n\n\n\n\nA blog post about implementing and testing the perceptron algorithm.\n\n\n\n\n\nApr 6, 2024\n\n\nJames Ohr\n\n\n\n\n\n\n\n\n\n\n\n\nDecision Making\n\n\n\n\n\nA blog post about optimal decisionmaking in the context of bank loans.\n\n\n\n\n\nMar 30, 2024\n\n\nJames Ohr\n\n\n\n\n\n\n\n\n\n\n\n\nClassifying Penguins\n\n\n\n\n\nA blog post about classifying penguin species based on physical characteristics.\n\n\n\n\n\nMar 29, 2024\n\n\nJames Ohr\n\n\n\n\n\n\n\n\n\n\n\n\nTimnit Gebru\n\n\n\n\n\nA new blog post that I just made!\n\n\n\n\n\nMar 10, 2023\n\n\nPhil Chodrow\n\n\n\n\n\n\n\n\n\n\n\n\nSecond Post\n\n\n\n\n\nA new blog post that I just made!\n\n\n\n\n\nMar 10, 2023\n\n\nPhil Chodrow\n\n\n\n\n\n\n\n\n\n\n\n\nHello Blog\n\n\n\n\n\nAn example blog post illustrating the key techniques you’ll need to demonstrate your learning in CSCI 0451.\n\n\n\n\n\nJan 10, 2023\n\n\nPhil Chodrow\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/classifying-penguins/ClassifyingPenguins.html",
    "href": "posts/classifying-penguins/ClassifyingPenguins.html",
    "title": "Classifying Penguins",
    "section": "",
    "text": "Blog Post 1: Classifying Palmer Penguins\nAbstract:\nThis post seeks to identify what qualitative and quantative features we should select to achieve a 100% accuracy rate using a machine learning model (specifically a logistic regression model) to predict a penguin’s species. We exhaustively test combinations of available features to find the combination that leads to the highest accuracy on training data. The features found to lead to a model with 100% accuracy on the test dataset were the island a penguin was on, the penguins’ culmen length, and their culmen depth.\nI have neither given nor received unauthorized aid on this assignment - James Ohr\n\nimport pandas as pd\n\ntrain_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/train.csv\"\ntrain = pd.read_csv(train_url)\n\n\ntrain.head()\n\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\n\n\n0\nPAL0809\n31\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN63A1\nYes\n11/24/08\n40.9\n16.6\n187.0\n3200.0\nFEMALE\n9.08458\n-24.54903\nNaN\n\n\n1\nPAL0809\n41\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN74A1\nYes\n11/24/08\n49.0\n19.5\n210.0\n3950.0\nMALE\n9.53262\n-24.66867\nNaN\n\n\n2\nPAL0708\n4\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN32A2\nYes\n11/27/07\n50.0\n15.2\n218.0\n5700.0\nMALE\n8.25540\n-25.40075\nNaN\n\n\n3\nPAL0708\n15\nGentoo penguin (Pygoscelis papua)\nAnvers\nBiscoe\nAdult, 1 Egg Stage\nN38A1\nYes\n12/3/07\n45.8\n14.6\n210.0\n4200.0\nFEMALE\n7.79958\n-25.62618\nNaN\n\n\n4\nPAL0809\n34\nChinstrap penguin (Pygoscelis antarctica)\nAnvers\nDream\nAdult, 1 Egg Stage\nN65A2\nYes\n11/24/08\n51.0\n18.8\n203.0\n4100.0\nMALE\n9.23196\n-24.17282\nNaN\n\n\n\n\n\n\n\n\nThe below code preprocesses the data: it assigns a unique numerical value to each unique category in the “Species” column, removes variables that are not of interest, removes observations where the value for “Sex” is “.”, and removes any observations with missing variable values.\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nle.fit(train[\"Species\"])\n\ndef prepare_data(df):\n  df = df.drop([\"studyName\", \"Sample Number\", \"Individual ID\", \"Date Egg\", \"Comments\", \"Region\"], axis = 1)\n  df = df[df[\"Sex\"] != \".\"]\n  df = df.dropna()\n  y = le.transform(df[\"Species\"])\n  df = df.drop([\"Species\"], axis = 1)\n  df = pd.get_dummies(df)\n  return df, y\n\nX_train, y_train = prepare_data(train)\n\nX_train.head()\n\n\n\n\n\n\n\n\n\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nIsland_Biscoe\nIsland_Dream\nIsland_Torgersen\nStage_Adult, 1 Egg Stage\nClutch Completion_No\nClutch Completion_Yes\nSex_FEMALE\nSex_MALE\n\n\n\n\n0\n40.9\n16.6\n187.0\n3200.0\n9.08458\n-24.54903\n0\n1\n0\n1\n0\n1\n1\n0\n\n\n1\n49.0\n19.5\n210.0\n3950.0\n9.53262\n-24.66867\n0\n1\n0\n1\n0\n1\n0\n1\n\n\n2\n50.0\n15.2\n218.0\n5700.0\n8.25540\n-25.40075\n1\n0\n0\n1\n0\n1\n0\n1\n\n\n3\n45.8\n14.6\n210.0\n4200.0\n7.79958\n-25.62618\n1\n0\n0\n1\n0\n1\n1\n0\n\n\n4\n51.0\n18.8\n203.0\n4100.0\n9.23196\n-24.17282\n0\n1\n0\n1\n0\n1\n0\n1\n\n\n\n\n\n\n\n\n\nimport seaborn as sns\n#Creates a table showing means by island\ntrain.groupby([\"Island\", \"Species\"]).aggregate('mean')\n\nC:\\Users\\james\\AppData\\Local\\Temp\\ipykernel_33480\\3605326083.py:3: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n  train.groupby([\"Island\", \"Species\"]).aggregate('mean')\n\n\n\n\n\n\n\n\n\n\n\nSample Number\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\n\n\nIsland\nSpecies\n\n\n\n\n\n\n\n\n\n\n\nBiscoe\nAdelie Penguin (Pygoscelis adeliae)\n66.030303\n38.845455\n18.475758\n188.636364\n3711.363636\n8.788643\n-25.920138\n\n\nGentoo penguin (Pygoscelis papua)\n60.244898\n47.073196\n14.914433\n216.752577\n5039.948454\n8.247341\n-26.149389\n\n\nDream\nAdelie Penguin (Pygoscelis adeliae)\n90.622222\n38.826667\n18.306667\n190.133333\n3728.888889\n8.933945\n-25.769529\n\n\nChinstrap penguin (Pygoscelis antarctica)\n35.631579\n48.826316\n18.366667\n196.000000\n3743.421053\n9.331004\n-24.553401\n\n\nTorgersen\nAdelie Penguin (Pygoscelis adeliae)\n67.547619\n39.229268\n18.468293\n191.195122\n3712.804878\n8.846768\n-25.715095\n\n\n\n\n\n\n\n\nThe above table shows that each island has a different combination of penguin species. It’s worth nothing that within each island, the different penguin species seem to have notable differences in culmen length and flipper length. The only island on which body mass and culmen depth distinguish its two species of resident penguins is Biscoe.\n\n#Creates a scatterplot whose axes are culmen depth and body mass, with points colored by species\nsns.scatterplot(data=train, x=\"Culmen Depth (mm)\", y=\"Body Mass (g)\", hue=\"Species\")\n\n\n\n\n\n\n\n\nThe above figure shows that there’s a clear divide between Gentoo penguins and the other two penguin species in body mass–Gentoo penguins are heavier regardless of culmen depth. But controlling for the species, there’s a clear positive linear relationship between body mass and culmen depth. Adelie and Chinstrap penguins seem to have the same linear relationship between body mass and culmen depth.\n\n#Creates a scatterplot whose axes are flipper length and body mass, with points colored by island\nsns.scatterplot(data=train, x=\"Flipper Length (mm)\", y=\"Body Mass (g)\", hue=\"Island\")\n\n\n\n\n\n\n\n\nThe above figure shows that regardless of the island a penguin is from, there’s a linear relationship between body mass and flipper length. But while penguins on Biscoe seem to have a greater range of body mass and flipper length, whereas penguins on Dream and Torgersen occupy a similar, tighter range.\nTraining the Model\nNow we choose three features of the data to achieve 100% testing accuracy. To do so, we use a nested for-loop to construct every possible combination of 1 qualitative feature and 2 quantitative features to use in training a logistic regression model. The outer for-loop sets a qualitative variable to use. The inner for-loop take a pair of quantitative variables from the all_quant_cols array.\nIncluded in the inner loop is an if-statement that ensures we keep track of the features that lead to the highest score. Those features are stored in the best_cols variable.\n\nfrom itertools import combinations\nfrom sklearn.linear_model import LogisticRegression\nbest_cols = [] #keeps track of the best features to use\nmax_score = 0 #keeps track of highest score so far\n\nall_qual_cols = ['Clutch Completion', 'Island']\nall_quant_cols = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Flipper Length (mm)', 'Body Mass (g)']\nLR = LogisticRegression(max_iter=10000)\nfor qual in all_qual_cols: \n  qual_cols = [col for col in X_train.columns if qual in col ]\n  for pair in combinations(all_quant_cols, 2):\n    cols = qual_cols + list(pair)\n    LR.fit(X_train[cols], y_train)\n    print(cols)\n    print(LR.score(X_train[cols], y_train))\n    if LR.score(X_train[cols], y_train) &gt; max_score:\n      max_score = LR.score(X_train[cols], y_train)\n      best_cols = cols\n\nLR.fit(X_train[best_cols], y_train)\n\n['Clutch Completion_No', 'Clutch Completion_Yes', 'Culmen Length (mm)', 'Culmen Depth (mm)']\n0.96484375\n['Clutch Completion_No', 'Clutch Completion_Yes', 'Culmen Length (mm)', 'Flipper Length (mm)']\n0.95703125\n['Clutch Completion_No', 'Clutch Completion_Yes', 'Culmen Length (mm)', 'Body Mass (g)']\n0.9453125\n['Clutch Completion_No', 'Clutch Completion_Yes', 'Culmen Depth (mm)', 'Flipper Length (mm)']\n0.81640625\n['Clutch Completion_No', 'Clutch Completion_Yes', 'Culmen Depth (mm)', 'Body Mass (g)']\n0.76953125\n['Clutch Completion_No', 'Clutch Completion_Yes', 'Flipper Length (mm)', 'Body Mass (g)']\n0.63671875\n['Island_Biscoe', 'Island_Dream', 'Island_Torgersen', 'Culmen Length (mm)', 'Culmen Depth (mm)']\n0.99609375\n['Island_Biscoe', 'Island_Dream', 'Island_Torgersen', 'Culmen Length (mm)', 'Flipper Length (mm)']\n0.9765625\n['Island_Biscoe', 'Island_Dream', 'Island_Torgersen', 'Culmen Length (mm)', 'Body Mass (g)']\n0.9765625\n['Island_Biscoe', 'Island_Dream', 'Island_Torgersen', 'Culmen Depth (mm)', 'Flipper Length (mm)']\n0.8828125\n['Island_Biscoe', 'Island_Dream', 'Island_Torgersen', 'Culmen Depth (mm)', 'Body Mass (g)']\n0.8359375\n['Island_Biscoe', 'Island_Dream', 'Island_Torgersen', 'Flipper Length (mm)', 'Body Mass (g)']\n0.75390625\n\n\nLogisticRegression(max_iter=10000)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LogisticRegressionLogisticRegression(max_iter=10000)\n\n\nCross-Validation\nThe below code uses a scikit-learn method to calculate cross-validation scores with five folds. The results are largely promising, with the lowest accuracy rate being 96%.\n\nfrom sklearn.model_selection import cross_val_score\n\ncv_scores_LR = cross_val_score(LR, X_train[best_cols], y_train, cv=5)\ncv_scores_LR\n\narray([0.98076923, 1.        , 1.        , 0.96078431, 1.        ])\n\n\nTesting\nThe below code loads test.csv, preprocesses the data with prepare_data, and scores the LR on the test data. The result is 100% accuracy.\n\ntest_url = \"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/test.csv\"\ntest = pd.read_csv(test_url)\n\nX_test, y_test = prepare_data(test)\nLR.score(X_test[best_cols], y_test)\n\n1.0\n\n\nDecision Regions\n\n#This section of code retrains the model on cols, which has the same features as best_col, just\n#with the columns rearranged so that Matplotlib doesn't return an error later in the next code block.\n\ncols = ['Culmen Length (mm)', 'Culmen Depth (mm)', 'Island_Biscoe', 'Island_Dream', 'Island_Torgersen']\nLR = LogisticRegression(max_iter=10000)\nLR.fit(X_train[cols], y_train)\n\nLogisticRegression(max_iter=10000)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LogisticRegressionLogisticRegression(max_iter=10000)\n\n\nThe below code defines a function, plot_regions, that creates multiple charts (the # is determined by how many qualitative variables there are), each with the same axes. The colors of different regions correspond to the species predictions made by the model, whereas the colors of observations correspond to actual species values.\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\nfrom matplotlib.patches import Patch\n\ndef plot_regions(model, X, y):\n    \n    x0 = X[X.columns[0]]\n    x1 = X[X.columns[1]]\n    qual_features = X.columns[2:]\n    \n    fig, axarr = plt.subplots(1, len(qual_features), figsize = (7, 3))\n\n    # Creates a grid\n    grid_x = np.linspace(x0.min(),x0.max(),501)\n    grid_y = np.linspace(x1.min(),x1.max(),501)\n    xx, yy = np.meshgrid(grid_x, grid_y)\n    \n    XX = xx.ravel()\n    YY = yy.ravel()\n\n    for i in range(len(qual_features)):\n      XY = pd.DataFrame({\n          X.columns[0] : XX,\n          X.columns[1] : YY\n      })\n\n      for j in qual_features:\n        XY[j] = 0\n\n      XY[qual_features[i]] = 1\n\n      p = model.predict(XY)\n      p = p.reshape(xx.shape)\n      \n      \n      # use contour plot to visualize the predictions\n      axarr[i].contourf(xx, yy, p, cmap = \"jet\", alpha = 0.2, vmin = 0, vmax = 2)\n      \n      ix = X[qual_features[i]] == 1\n      # plot the data\n      axarr[i].scatter(x0[ix], x1[ix], c = y[ix], cmap = \"jet\", vmin = 0, vmax = 2)\n      \n      axarr[i].set(xlabel = X.columns[0], \n            ylabel  = X.columns[1], \n            title = qual_features[i])\n      \n      patches = []\n      for color, spec in zip([\"red\", \"green\", \"blue\"], [\"Adelie\", \"Chinstrap\", \"Gentoo\"]):\n        patches.append(Patch(color = color, label = spec))\n\n      plt.legend(title = \"Species\", handles = patches, loc = \"best\")\n      \n      plt.tight_layout()\n\nplot_regions(LR, X_train[cols], y_train)\n\n\n\n\n\n\n\n\nAbove are the decision regions for the training data. We effectively control for the island a penguin is from to determine their species based on their culmen depth and length. The only inaccurately labeled point is a penguin on Dream with a slightly shorter culmen than its depth and would predict.\n\nplot_regions(LR, X_test[cols], y_test)\n\n\n\n\n\n\n\n\nOur 100% accuracy is reflected here–every plotted observation is correctly categorized into the region with the corresponding color.\nConfusion Matrix\nBelow is code to create a confusion matrix for our results. Given that there were no false positives or false negatives, we see a confusion matrix with non-zeros only on the diagonal.\n\nfrom sklearn.metrics import confusion_matrix\n\ny_test_pred = LR.predict(X_test[cols])\nC = confusion_matrix(y_test, y_test_pred)\nC\n\narray([[31,  0,  0],\n       [ 0, 11,  0],\n       [ 0,  0, 26]], dtype=int64)\n\n\nDiscussion\nIn this post, we found that, with a logistic regression model, the qualitative feature “Island” combined with culmen depth and culmen length can predict with great accuracy (100% accuracy on our test data) whether the penguin is of the Adelie, Chinstrap, or Gentoo species.\nThe original figures I created earlier in the post actually weren’t helpful in finding the best features. The body mass and flipper length relationship in particular was something that intuitively seemed right to me, but it wasn’t actually useful in helping predict penguin species.\nThrough this blog post, I’ve learned some basic features of scikit-learn, seaborn, Pandas, and Matplotlib. I’m not sure if I’m just not sufficiently comfortable with Matplotlib, but it gave me more trouble than the rest of the entire project. I had to re-train the model on a re-arranged set of column names (instead of best_cols) just to get it to stop giving me the same error. The most valuable aspect of it, I think, was just getting a better hang of the syntax and gaining familiarity with the tools we use in the class, especially scikit-learn."
  },
  {
    "objectID": "posts/example-blog-post/index.html",
    "href": "posts/example-blog-post/index.html",
    "title": "Hello Blog",
    "section": "",
    "text": "from source import Perceptron\nThis is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/example-blog-post/index.html#math",
    "href": "posts/example-blog-post/index.html#math",
    "title": "Hello Blog",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "posts/new-new-test-post/index.html",
    "href": "posts/new-new-test-post/index.html",
    "title": "Timnit Gebru",
    "section": "",
    "text": "from source import Perceptron\np = Perceptron()\n\nI did it!!\nnot implemented\nThis is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/new-new-test-post/index.html#math",
    "href": "posts/new-new-test-post/index.html#math",
    "title": "Timnit Gebru",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference."
  },
  {
    "objectID": "posts/newton-method/newton-method.html",
    "href": "posts/newton-method/newton-method.html",
    "title": "Newton’s Method for Logistic Regression",
    "section": "",
    "text": "%load_ext autoreload\n%autoreload 2\nfrom newton import LogisticRegression, GradientDescentOptimizer, NewtonOptimizer\nimport torch\nfrom matplotlib import pyplot as plt\n\nThe autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\nLink to newton.py in Github: https://github.com/jjr2024/github_jjr2024.github.io/blob/main/posts/newton-method/newton.py"
  },
  {
    "objectID": "posts/newton-method/newton-method.html#introduction",
    "href": "posts/newton-method/newton-method.html#introduction",
    "title": "Newton’s Method for Logistic Regression",
    "section": "Introduction",
    "text": "Introduction\nIn this blog post, I implement Newton’s method, an optimizer technique that’s an alternative to standard gradient descent. I run three experiments and find that Newton’s method works best with low numbers of observations, high noise, and relatively low alphas (learning rates). Then I consider the computational cost of Newton’s method vs. gradient descent and consider the impact of \\(p\\), the number of features, on the comparison between the two methods."
  },
  {
    "objectID": "posts/newton-method/newton-method.html#part-a-implement-newtonoptimizer",
    "href": "posts/newton-method/newton-method.html#part-a-implement-newtonoptimizer",
    "title": "Newton’s Method for Logistic Regression",
    "section": "Part A: Implement NewtonOptimizer",
    "text": "Part A: Implement NewtonOptimizer\nIn this section, we define functions that we will use in our experiments. classification_data generates data for a classication problem: n_points controls the number of observations generated. Noise determines the difficulty of the problem. p_dims controls the number of features.\nTrain() is a function to train our LR model. We can control the maximum number of iterations (max_iterations) and the learning rate (a).\nplot_perceptron_data and draw_line allow us to plot our data and our weight vector respectively to visualize our results.\n\ndef classification_data(n_points = 300, noise = 0.2, p_dims = 2):\n    \n    y = torch.arange(n_points) &gt;= int(n_points/2)\n    y = 1.0*y\n    X = y[:, None] + torch.normal(0.0, noise, size = (n_points,p_dims))\n    X = torch.cat((X, torch.ones((X.shape[0], 1))), 1)\n    \n    return X, y\n\n\nLR = LogisticRegression() \nopt = NewtonOptimizer(LR)\n\nloss_vec = []\n\ndef train(X, y, max_iterations = 1000, a = 0.1):\n    for _ in range(max_iterations):\n        loss = LR.loss(X, y) \n        loss_vec.append(loss)\n        opt.step(X, y, a)\n\n\ndef plot_perceptron_data(X, y, ax):\n    assert X.shape[1] == 3, \"This function only works for data created with p_dims == 2\"\n    targets = [0, 1]\n    markers = [\"o\" , \",\"]\n    for i in range(2):\n        ix = y == targets[i]\n        ax.scatter(X[ix,0], X[ix,1], s = 20,  c = y[ix], facecolors = \"none\", edgecolors = \"darkgrey\", cmap = \"BrBG\", vmin = -2, vmax = 2, alpha = 0.5, marker = markers[i])\n    ax.set(xlabel = r\"$x_1$\", ylabel = r\"$x_2$\")\n\n\ndef draw_line(w, x_min, x_max, ax, **kwargs):\n    w_ = w.flatten()\n    x = torch.linspace(x_min, x_max, 101)\n    y = -(w_[0]*x + w_[2])/w_[1]\n    l = ax.plot(x, y, **kwargs)"
  },
  {
    "objectID": "posts/newton-method/newton-method.html#part-b-perform-experiments",
    "href": "posts/newton-method/newton-method.html#part-b-perform-experiments",
    "title": "Newton’s Method for Logistic Regression",
    "section": "Part B: Perform Experiments",
    "text": "Part B: Perform Experiments\n\nExperiment 1: Appropriate Alpha -&gt; Converge to Correct Weight Vector\nIn the below code, we generate our classification data and calculate the loss vector when we use our Newton optimizer. The last item in the loss vector is near-zero.\n\nLR = LogisticRegression() \nopt = NewtonOptimizer(LR)\n\nloss_vec = []\n\nX, y = classification_data(n_points = 100, noise = 0.1, p_dims = 2)\n\ntrain(X,y,1000,a=0.9)\n\nprint(\"Last Loss: \" + str(loss_vec[len(loss_vec)-1]))\n\nLast Loss: tensor(5.4466e-05)\n\n\nIn the below code, we save the loss vector we just computed into loss_vec2 and then compute, on the same classification data, the loss vector when we use standard gradient descent. Then we visualize both loss vectors.\n\nLR2 = LR\nLR = LogisticRegression() \nopt = GradientDescentOptimizer(LR)\n\nloss_vec2 = loss_vec\nloss_vec = []\n\n#Standard gradient descent\nfor _ in range(1000):\n    loss = LR.loss(X, y) \n    loss_vec.append(loss)\n    opt.step(X, y, 0.9, 0.0)\n\nplt.plot(loss_vec, color = \"slategrey\")\nplt.plot(loss_vec2, color = \"blue\")\nplt.scatter(torch.arange(len(loss_vec)), loss_vec, color = \"slategrey\")\nplt.scatter(torch.arange(len(loss_vec2)), loss_vec2, color = \"blue\")\nlabs = plt.gca().set(xlabel = \"Perceptron Iteration (Updates Only)\", ylabel = \"Loss\")\n\n\n\n\n\n\n\n\nThere are two key takeaways for the above graph of the loss vectors.\nFirst, we see that with alpha = 0.8, we eventually converge to a weight vector that produces a near-zero loss. Second, while the blue line (loss vector with Newton’s Method) and the grey line (loss vector with standard gradient descent) have marked differences in early iterations, they eventually converge to a zero/near-zero loss.\n\nfig, ax = plt.subplots(1, 1)\nplot_perceptron_data(X, y, ax)\n\ndraw_line(LR.w, 0, 1, ax, color = \"black\", linestyle = \"dashed\", label = \"weight vector w\")\ndraw_line(LR2.w, 0, 1, ax, color = \"blue\", linestyle = \"dashed\", label = \"weight vector w\")\n\n\n\n\n\n\n\n\nWe see above that standard gradient descent (black line) and Newton’s method (blue line) have converged to very similar weight vectors. Both successfully separate our data into two categories.\n\n\nExperiment 2: Faster Convergence\nBelow, we run an experiment comparing standard gradient descent to the Newton’s method in a context in which the latter has far faster convergence than the former.\n\nX, y = classification_data(n_points = 6, noise = 1, p_dims = 2)\n\nLR = LogisticRegression() \nopt = NewtonOptimizer(LR)\n\nloss_vec = []\n\nmax_iterations = 100\ntrain(X,y,max_iterations,a=0.5)\nloss_vec2 = loss_vec\nLR2 = LR\nprint(\"Last Loss: \" + str(loss_vec[len(loss_vec)-1]))\n\nLast Loss: tensor(0.5748)\n\n\n\nLR = LogisticRegression() \nopt = GradientDescentOptimizer(LR)\n\nloss_vec = []\n\n#Standard gradient descent\nfor _ in range(max_iterations):\n    loss = LR.loss(X, y) \n    loss_vec.append(loss)\n    opt.step(X, y, 0.5, 0.0)\n\nplt.plot(loss_vec, color = \"slategrey\")\nplt.plot(loss_vec2, color = \"blue\")\nplt.scatter(torch.arange(len(loss_vec)), loss_vec, color = \"slategrey\")\nplt.scatter(torch.arange(len(loss_vec2)), loss_vec2, color = \"blue\")\nlabs = plt.gca().set(xlabel = \"Perceptron Iteration (Updates Only)\", ylabel = \"Loss\")\n\n\n\n\n\n\n\n\nNewton’s method (blue line) converges far faster than standard gradient descent (grey line) when we have a very small number of data points and very high noise.\n\n\nExperiment 3: Failure to Converge\nWhen alpha is too high, Newton’s method fails to converge. In the below experiment, we create classification data with just 6 observations and set alpha = 15.\n\nX, y = classification_data(n_points = 6, noise = 0.3, p_dims = 2)\n\nLR = LogisticRegression() \nopt = NewtonOptimizer(LR)\n\nloss_vec = []\nalpha = 15\n\nmax_iterations = 100\nfor _ in range(max_iterations):\n    loss = LR.loss(X, y) \n    loss_vec.append(loss)\n    opt.step(X, y, alpha)\n    \n\nprint(\"Matrix Inverse of Hessian: \" + str(torch.linalg.inv(LR.hessian(X))))\nprint(\"Final Weights: \" + str(LR.w))\nprint(\"Sigmoid(Scores): \" + str(torch.sigmoid(LR.score(X))))\nprint(\"Log of One Less Sigmoid(Scores): \" + str(torch.log(1 - torch.sigmoid(LR.score(X)))))\nprint(\"Last Loss: \" + str(loss_vec[len(loss_vec)-1]))\n\nplt.plot(loss_vec, color = \"slategrey\")\nplt.scatter(torch.arange(len(loss_vec)), loss_vec, color = \"slategrey\")\nlabs = plt.gca().set(xlabel = \"Perceptron Iteration (Updates Only)\", ylabel = \"Loss\")\n\nMatrix Inverse of Hessian: tensor([[ 1.5264e+08, -1.2952e+10, -4.2737e+08],\n        [-5.0249e+09, -2.0723e+11, -4.6904e+09],\n        [-1.9267e+08, -2.4107e+09, -1.5962e+07]])\nFinal Weights: tensor([-7.5370e+17,  1.6740e+19,  7.1238e+17])\nSigmoid(Scores): tensor([0.5000, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000])\nLog of One Less Sigmoid(Scores): tensor([-0.6931,  0.0000,    -inf,    -inf,    -inf,    -inf])\nLast Loss: tensor(nan)\n\n\n\n\n\n\n\n\n\nWith a high alpha relative to the number of datapoints, we get a strange loss vector and fail to converge. Above the chart is a series of print statements illustrating the problem. Our matrix inverse of the hessian ends up with values with extremely high absolute values because, multiplied by a high alpha, these values are embedded into the weights, which become increasingly large with each iteration.\nThe weights are enormous, leading to extremely high scores, which translate into extremely negative values when we calculate the log of (1 - sigmoid(scores)). Those extremely negative values are treated by Python as negative infinity. By attempting to run calculations with these -inf values, we end up with NaNs."
  },
  {
    "objectID": "posts/newton-method/newton-method.html#part-c-operation-counting",
    "href": "posts/newton-method/newton-method.html#part-c-operation-counting",
    "title": "Newton’s Method for Logistic Regression",
    "section": "Part C: Operation Counting",
    "text": "Part C: Operation Counting\n\nProblem\nWe are given the following:\n\nComputational units for each calculation\n\n\\(L = c\\)\n\\(\\nabla L = 2c\\)\n\\(Hessian = pc\\)\nInvert a \\(p \\times p\\) matrix \\(= k_1p^\\gamma\\)\nNewton’s method matrix-vector multiplication \\(= k_2p^2\\)\n\nNewton’s method converges in \\(t_{nm}\\) steps\nGradient descent converges in \\(t_{gd}\\) steps\n\nWe want to know how much smaller \\(t_{nm}\\) needs to be than \\(t_{gd}\\) for Newton’s method to require fewer computational units to complete. We also want to know if using Newton’s method ever pays off if \\(p\\) is very large.\n\n\nSolution\nFirst we set up a very abstract equation. Then we unravel the abstracted components of the inequality.\n\nTotal computational cost of Newton’s Method \\(=\\) Total computational cost of gradient descent\n\nFor both sides of the equation, total computational cost = number of iterations (i.e., steps) times cost per iteration.\n\n\\(t_{nm} (c + 2c + pc + k_1p^\\gamma + k_2p^2) = t_{gd} (c + 2c)\\)\n\\(t_{nm} (3c + pc + k_1p^\\gamma + k_2p^2) = t_{gd} (3c)\\)\n\\(t_{nm} = t_{gd}*\\frac{3c}{3c + pc + k_1p^\\gamma + k_2p^2}\\)\n\nWith this equation, we know \\(t_{nm}\\) must be \\(\\frac{3c}{3c + pc + k_1p^\\gamma + k_2p^2}\\) of \\(t_{gd}\\) for the computational costs to be equal. So \\(t_{nm}\\) needs to be less than \\(\\frac{3c}{3c + pc + k_1p^\\gamma + k_2p^2}\\) of \\(t_{gd}\\) for Newton’s method to be computationally cheaper than gradient descent.\nThe fraction shows that as p increases in size, the denominator of the right-hand-side fraction in step 4 increases. So the entire fraction shrinks in value. In other words, \\(t_{nm}\\) must become an even smaller percentage of \\(t_{gd}\\). Therefore, when \\(p\\) becomes very large, it seems unlikely that using Newton’s method will pay off."
  },
  {
    "objectID": "posts/newton-method/newton-method.html#part-d-writing",
    "href": "posts/newton-method/newton-method.html#part-d-writing",
    "title": "Newton’s Method for Logistic Regression",
    "section": "Part D: Writing",
    "text": "Part D: Writing\nIn this post, I found Newton’s method was a computationally expensive but faster (in some cases) alternative to gradient descent. The number of observations, the difficulty of the classification problem (noise), and the learning rate all impacted the relative performance of Newton’s method vs. gradient descent.\nI continued to grapple with linear algebra and programming implementations of it in this post. Implementing Newton’s method wasn’t painless, but it went about as smoothly as implementing logistic regression. The similarity of this post with perceptron and logistic regression implementation helped significantly in making that happen. I gained more familiarity with analyzing the components of my model via the analysis in experiment 3. It helped significantly with my understanding of this model to break down, step-by-step, why the loss became NaN."
  }
]